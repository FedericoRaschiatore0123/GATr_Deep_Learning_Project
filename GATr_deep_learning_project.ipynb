{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoRaschiatore0123/GATr_Deep_Learning_Project/blob/main/GATr_deep_learning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "RT7SSYdrEBj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/FedericoRaschiatore0123/GATr_Deep_Learning_Project.git"
      ],
      "metadata": {
        "id": "yRyVdbVkiufV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d6a9068-765f-493a-b7e6-31293983854a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GATr_Deep_Learning_Project'...\n",
            "remote: Enumerating objects: 4338, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "Receiving objects: 100% (4338/4338), 1.70 GiB | 22.00 MiB/s, done.\n",
            "remote: Total 4338 (delta 172), reused 140 (delta 108), pack-reused 4120\u001b[K\n",
            "Resolving deltas: 100% (243/243), done.\n",
            "Updating files: 100% (4005/4005), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "!pip install pytorch_lightning --quiet\n",
        "!pip install h5py\n",
        "!pip install trimesh\n",
        "!pip install torch_geometric\n",
        "!pip install pyquaternion\n",
        "!pip install clifford\n",
        "!pip install einops\n",
        "\n",
        "from torchmetrics.classification import BinaryAccuracy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch_geometric.data\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import random_split, ConcatDataset, Subset\n",
        "from pyquaternion import Quaternion\n",
        "import clifford as cf\n",
        "import pytorch_lightning as pl\n",
        "import math\n",
        "from einops import rearrange\n",
        "from torch.nn import GELU\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import h5py\n",
        "import os\n",
        "import trimesh\n",
        "import random"
      ],
      "metadata": {
        "id": "MG8SPGozwpkB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5498c287-f571-4a83-fb02-baddc1a306e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Global Variables"
      ],
      "metadata": {
        "id": "iI9E2jDSEHKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary of global variables\n",
        "global_variables = {\n",
        "\n",
        "    'single_path' : '/content/GATr_Deep_Learning_Project/single/',\n",
        "    'bifurcating_path' : '/content/GATr_Deep_Learning_Project/bifurcating/',\n",
        "\n",
        "    'length_data' : 100,\n",
        "    'mv_dimension' : 16,\n",
        "    'mv_channels' : 4,\n",
        "    'hidden_dim_mv' : 8,\n",
        "\n",
        "    'num_heads' : 2,\n",
        "    'out_channels' : 1,\n",
        "    'num_classes' : 2,\n",
        "    \"patience\" : 3,\n",
        "    \"factor\" : 0.1,\n",
        "    \"dropout\" : 0.1,\n",
        "\n",
        "    'batch_size' :  64,\n",
        "    'num_workers' : 2,\n",
        "\n",
        "    'dim_input_MLP' : 10,\n",
        "    'batch_size_MLP' : 32,\n",
        "\n",
        "    'dim_GA' : 16,\n",
        "    'hidden_dim' : 8,\n",
        "\n",
        "    'geometric_guidance' : '/content/GATr_Deep_Learning_Project/data/geometric_product.pt',\n",
        "    'outer_guidance' : '/content/GATr_Deep_Learning_Project/data/outer_product.pt',\n",
        "}"
      ],
      "metadata": {
        "id": "nuLFZjyREJet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get device"
      ],
      "metadata": {
        "id": "juxtyP3_Dxb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "YMMTiCupDwpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Show data"
      ],
      "metadata": {
        "id": "BtUQ2EPCD5uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Samples of the dataset are shown for both classes (single, bifurcating) using trimesh\n",
        "\n",
        "single_list = os.listdir(global_variables['single_path'])\n",
        "\n",
        "with h5py.File(global_variables['single_path'] + single_list[random.randint(0, len(single_list))] , 'r') as file:\n",
        "\n",
        "    vertices = np.array(file['pos'])\n",
        "    faces = np.array(file['face'])\n",
        "\n",
        "mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
        "mesh.show()"
      ],
      "metadata": {
        "id": "NKNytRO4QNcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bifurcating_list = os.listdir(global_variables['bifurcating_path'])\n",
        "\n",
        "with h5py.File(global_variables['bifurcating_path'] + bifurcating_list[random.randint(0, len(bifurcating_list))] , 'r') as file:\n",
        "    vertices = np.array(file['pos'])\n",
        "    faces = np.array(file['face'])\n",
        "\n",
        "mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
        "mesh.show()"
      ],
      "metadata": {
        "id": "5jCvEEzl6Yds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_balancing(dataset):\n",
        "  \"\"\"\n",
        "  This function is used to visualize the distribution of the data between the two classes through an histogram.\n",
        "  Input:\n",
        "    dataset (torch.Tensor)\n",
        "\n",
        "  Output:\n",
        "    histogram representing the distribution of the samples\n",
        "  \"\"\"\n",
        "  label = []\n",
        "  for _ , element in enumerate(dataset):\n",
        "    label.append(element[-1])\n",
        "\n",
        "  categories = ['Single ' +  str(label.count(0)), 'Bifurcating ' +  str(label.count(1))]\n",
        "\n",
        "  fig, ax = plt.subplots(figsize = (8,5))\n",
        "\n",
        "  bars = ax.bar(\n",
        "      categories,\n",
        "      [label.count(0), label.count(1)],\n",
        "      align = 'center'\n",
        "    )\n",
        "\n",
        "  ax.set_xlabel('Labels')\n",
        "  ax.set_ylabel('Number of occurences')\n",
        "\n",
        "  plt.ylim(ymax = len(label))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "QbFI-8mcrnxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confusion_matrix_display(true_label, pred_label):\n",
        "\n",
        "  cm = confusion_matrix(true_label, pred_label)\n",
        "\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "  disp.plot(cmap=plt.cm.Blues)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "CdpaRAU7lAde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scatter_plot():\n",
        "\n",
        "  single_list = os.listdir(global_variables['single_path'])\n",
        "  bifurcating_list = os.listdir(global_variables['bifurcating_path'])\n",
        "\n",
        "  single_press = []\n",
        "  single_wss = []\n",
        "  bifurcating_press = []\n",
        "  bifurcating_wss = []\n",
        "\n",
        "  for single_file in single_list:\n",
        "\n",
        "    with h5py.File(global_variables['single_path'] + single_file , 'r') as file:\n",
        "\n",
        "      single_press.append(np.array(file['pressure']).mean() * 1e-3)\n",
        "\n",
        "      single_wss.append(np.array(file['wss']).mean())\n",
        "\n",
        "  for bifurcarting_file in bifurcating_list:\n",
        "\n",
        "    with h5py.File(global_variables['bifurcating_path'] + bifurcarting_file , 'r') as file:\n",
        "\n",
        "      bifurcating_press.append(np.array(file['pressure']).mean() * 1e-3)\n",
        "\n",
        "      bifurcating_wss.append(np.array(file['wss']).mean())\n",
        "\n",
        "  pressure = [single_press, bifurcating_press]\n",
        "  wss = [single_wss, bifurcating_wss]\n",
        "\n",
        "  fig, ax = plt.subplots(figsize = (10,7))\n",
        "\n",
        "  ax.scatter(\n",
        "      single_press,\n",
        "      single_wss,\n",
        "      label = 'Single',\n",
        "      alpha = 0.3\n",
        "    )\n",
        "  ax.scatter(\n",
        "      bifurcating_press,\n",
        "      bifurcating_wss,\n",
        "      label = 'Bifurcating',\n",
        "      alpha = 0.3\n",
        "    )\n",
        "\n",
        "  ax.set_title('Scatterplot between mean WSS e Pressure')\n",
        "\n",
        "  ax.legend()\n",
        "  plt.show()\n",
        "\n",
        "scatter_plot()"
      ],
      "metadata": {
        "id": "rfK6GHtnB8jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP baseline architecture\n",
        "\n",
        "To have a baseline to compare the results of the GATr against, a basic MLP architecture is implemented.\n",
        "\n",
        "\n",
        "The network is composed by a feature extraction block, in which mulitple convolutional layers are used to increase the number of features from 10 to 64 and by a fully connected block.\n",
        "\n"
      ],
      "metadata": {
        "id": "2-LGZvaTsC5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation\n",
        "\n",
        "First, the data is pre-processed. Each sample is processed separately: the maximum number of points considered for each sample is defined by global_variables['length_data'], the features $\\texttt{pos}$, $\\texttt{wss}$ and $\\texttt{pressure}$ are thus standardized as:\n",
        " $$ std(x) = \\frac{x - \\bar{x}}{\\sigma(x)}, $$ where $\\bar{x}$ and $\\sigma(x)$ represent the mean and standard deviation of feature variable $x$ over all the points of the sample. The feature $\\texttt{inlet_idcs}$ was deliberately left out as was considered marginal compared to the other features: as it is shown in the scatter plot between mean $\\texttt{wss}$ and $\\texttt{pressure}$, the data appears to be well separated even without the $\\texttt{inlet_idcs}$ feature. The standardized data is thus concatenated in a torch tensor of size $\\texttt{[1, global_variables['length_data'], 10]}$, for each sample."
      ],
      "metadata": {
        "id": "SFE75DxKtJtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparation of the data for the MLP architecture\n",
        "def prepare_data_MLP(sample_path):\n",
        "  \"\"\"\n",
        "  Embeds the artery sample into a concatenation of 4 16-dimensional multivectors in G_{3,0,1}.\n",
        "  Each of the 4 multivectors embeds a different feature of the artery: pos, face, wss, pressure\n",
        "  The data is standardized before the embedding\n",
        "  Input:\n",
        "    sample_path: path to the artery sample saved in hdf5 format\n",
        "  Output:\n",
        "    sample_embedding: torch.Tensor of size (1, length_data, 4, 16)\n",
        "        where length_data is the number of points in the samples considered for the embedding\n",
        "  \"\"\"\n",
        "\n",
        "  with h5py.File(sample_path, 'r') as f:\n",
        "    # extract torch tensor for pos\n",
        "    pos_data = f['pos'][:global_variables['length_data']]\n",
        "    pos_torch = torch.tensor(pos_data[:])\n",
        "    pos_torch_norm = (pos_torch - torch.mean(pos_torch)) / torch.std(pos_torch)\n",
        "\n",
        "    # extract torch tensor for face\n",
        "    face_data = f['face'][:global_variables['length_data']]\n",
        "    face_torch = torch.tensor(face_data[:])\n",
        "\n",
        "    # extract torch tensor for wss\n",
        "    wss_data = f['wss'][:global_variables['length_data']]\n",
        "    wss_torch = torch.tensor(wss_data[:])\n",
        "    wss_torch_norm = (wss_torch - torch.mean(wss_torch)) / torch.std(wss_torch)\n",
        "\n",
        "    # extract torch tensor for pressure\n",
        "    pressure_data = f['pressure'][:global_variables['length_data']]\n",
        "    pressure_torch = torch.tensor(pressure_data[:])\n",
        "    pressure_torch_norm = (pressure_torch - torch.mean(pressure_torch)) / torch.std(pressure_torch)\n",
        "    pressure_torch_norm = pressure_torch_norm.unsqueeze(1)\n",
        "\n",
        "    data_sample = torch.cat([pos_torch_norm, face_torch, pressure_torch_norm, wss_torch_norm], dim = 1)\n",
        "    data_sample = data_sample.unsqueeze(0)\n",
        "\n",
        "  return data_sample"
      ],
      "metadata": {
        "id": "vVnsNJ5os5Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data module for the MLP architecture\n",
        "\n",
        "class DataModuleMLP(pl.LightningDataModule):\n",
        "  \"\"\"\n",
        "  Class DataModule used for handling data loading, preparation, and splitting\n",
        "  into training, validation, and test sets.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, path_single, path_bifurcating):\n",
        "\n",
        "    super(DataModuleMLP,self).__init__()\n",
        "\n",
        "    self.single_data_path = path_single\n",
        "    self.bifurcating_data_path = path_bifurcating\n",
        "    self.dataset = None\n",
        "\n",
        "  def prepare_data(self):\n",
        "    \"\"\"\n",
        "    This method is used for loading and shuffling data\n",
        "    \"\"\"\n",
        "    single_dataset, label_single = self.load_data(self.single_data_path,  bifurcating=False)\n",
        "    bifurcating_dataset, label_bifurcating = self.load_data(self.bifurcating_data_path,  bifurcating=True)\n",
        "    indices = torch.randperm(label_single.shape[0] + label_bifurcating.shape[0])\n",
        "\n",
        "    self.dataset = self.shuffle_and_combine_datasets(single_dataset, bifurcating_dataset, indices)\n",
        "    self.label = self.shuffle_and_combine_datasets(label_single, label_bifurcating, indices)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    \"\"\"\n",
        "    This method is used for setting up the datasets for training, validation, and testing.\n",
        "\n",
        "    Inputs:\n",
        "      stage (str, optional): Stage of the training process (fit, test). Default is None.\n",
        "    \"\"\"\n",
        "    train, validation, test , predict = self.split_dataset(list(zip(self.dataset, self.label)))\n",
        "\n",
        "    if stage == \"fit\" or stage is None:\n",
        "      self.train_dataset = train\n",
        "      self.validation_dataset = validation\n",
        "\n",
        "    if stage == \"test\" or stage is None:\n",
        "      self.test_dataset = test\n",
        "\n",
        "    if stage == \"predict\" or stage is None:\n",
        "      self.predict_dataset = predict\n",
        "\n",
        "  def load_data(self, path, bifurcating=False):\n",
        "    # TODO: ask Federico about the bifurcating flag\n",
        "    \"\"\"\n",
        "    This method is used for loading the data and assigning a label to each sample.\n",
        "\n",
        "    Inputs:\n",
        "      path (str): Path to the dataset.\n",
        "      bifurcating (bool):\n",
        "\n",
        "    Output:\n",
        "      data (torch.Tensor): Loaded data.\n",
        "      label (torch.Tensor): Corresponding labels.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for file in os.listdir(path):\n",
        "        data.append(prepare_data_MLP(path + file))\n",
        "\n",
        "    label = torch.ones(len(data)) if bifurcating else torch.zeros(len(data))\n",
        "    data = torch.stack(data).squeeze()\n",
        "\n",
        "    return data , label\n",
        "\n",
        "\n",
        "  def shuffle_and_combine_datasets(self, dataset1, dataset2, indices):\n",
        "      \"\"\"\n",
        "      This method is used to combine and shuffle the datasets\n",
        "      Input:\n",
        "        dataset1 (torch.Tensor): first dataset\n",
        "        dataset2 (torch.Tensor): second dataset\n",
        "        indices (torch.Tensor): indices used for shuffling\n",
        "\n",
        "      Output:\n",
        "        shuffled_dataset (torch.Tensor): shuffled dataset\n",
        "      \"\"\"\n",
        "      combined_dataset = ConcatDataset([dataset1, dataset2])\n",
        "      shuffled_dataset = Subset(combined_dataset, indices)\n",
        "\n",
        "      return shuffled_dataset\n",
        "\n",
        "  def split_dataset(self, dataset, train_ratio=0.7, validation_ratio=0.1, test_ratio=0.1, prediction_ratio = 0.1):\n",
        "      \"\"\"\n",
        "      This method is used to split the dataset into training, validation and test set\n",
        "      Inputs:\n",
        "        dataset (torch.Tensor): entire dataset\n",
        "        train_ratio (float)\n",
        "        validation_ratio (float)\n",
        "        test_ratio (float)\n",
        "\n",
        "      Output:\n",
        "        train_dataset, validation_dataset, test_dataset (torch.Tensor)\n",
        "      \"\"\"\n",
        "\n",
        "      total_size = len(dataset)\n",
        "      train_size = int(total_size * train_ratio)\n",
        "      validation_size = int(total_size * validation_ratio)\n",
        "      test_size = int(total_size * test_ratio)\n",
        "      pred_size = total_size - train_size - validation_size - test_size\n",
        "\n",
        "      train_dataset, validation_dataset, test_dataset , predict_dataset = random_split(dataset, [train_size, validation_size, test_size, pred_size])\n",
        "\n",
        "      return train_dataset, validation_dataset, test_dataset, predict_dataset\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      \"\"\"\n",
        "      This method returns the train dataloader\n",
        "      \"\"\"\n",
        "      return DataLoader(\n",
        "          self.train_dataset,\n",
        "          shuffle = True,\n",
        "          batch_size = global_variables['batch_size_MLP'],\n",
        "          num_workers = global_variables['num_workers'],\n",
        "          drop_last = True\n",
        "        )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "      \"\"\"\n",
        "      This method returns the validation dataloader\n",
        "      \"\"\"\n",
        "      return DataLoader(\n",
        "          self.validation_dataset,\n",
        "          shuffle = False,\n",
        "          batch_size = global_variables['batch_size_MLP'],\n",
        "          num_workers = global_variables['num_workers'],\n",
        "          drop_last = True\n",
        "        )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "      \"\"\"\n",
        "      This method returns the test dataloader\n",
        "      \"\"\"\n",
        "      return DataLoader(\n",
        "          self.test_dataset,\n",
        "          shuffle = False,\n",
        "          batch_size = global_variables['batch_size_MLP'],\n",
        "          num_workers = global_variables['num_workers'],\n",
        "          drop_last = True\n",
        "        )\n",
        "\n",
        "  def predict_dataloader(self):\n",
        "      \"\"\"\n",
        "      This method returns the predict dataloader\n",
        "      \"\"\"\n",
        "      return DataLoader(\n",
        "            self.predict_dataset,\n",
        "            shuffle = False,\n",
        "            batch_size = global_variables['batch_size_MLP'],\n",
        "            num_workers = global_variables['num_workers'],\n",
        "            drop_last = True\n",
        "          )\n",
        "\n",
        "  def train_dataset(self):\n",
        "    \"\"\"\n",
        "    This method returns the training dataset\n",
        "    \"\"\"\n",
        "    return self.train_dataset\n",
        "\n",
        "  def val_dataset(self):\n",
        "    \"\"\"\n",
        "    This method returns the validation dataset\n",
        "    \"\"\"\n",
        "    return self.val_dataset\n",
        "\n",
        "  def test_dataset(self):\n",
        "    \"\"\"\n",
        "    This method returns the test dataset\n",
        "    \"\"\"\n",
        "    return self.test_dataset\n",
        "\n",
        "  def predict_dataset(self):\n",
        "    \"\"\"\n",
        "    This method returns the predict dataset\n",
        "    \"\"\"\n",
        "    return self.predict_dataset"
      ],
      "metadata": {
        "id": "XuBxdhwR2WSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the architecture"
      ],
      "metadata": {
        "id": "3cLvzab846pD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class baseline_MLP(nn.Module):\n",
        "    def __init__(self, num_points, input_dim, num_classes, dropout):\n",
        "        super(baseline_MLP, self).__init__()\n",
        "\n",
        "        # Feature extraction block\n",
        "        self.convolutional_block = nn.Sequential(\n",
        "            nn.Conv1d(num_points, 16, 1),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(16, 32, 1),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(32, 64, 1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.AdaptiveMaxPool1d(1)\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64, 16),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.BatchNorm1d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(8, num_classes-1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(\"Input shape:\", x.shape)\n",
        "        #n_pts = x.size()[2]\n",
        "        x = self.convolutional_block(x)\n",
        "        #print(\"Input shape after input transform:\", x.shape)\n",
        "        x = x.max(dim=-1, keepdim=True)[0]\n",
        "        #print(\"Input shape after max:\", x.shape)\n",
        "        x = x.view(-1, 64)\n",
        "        #print(\"Input shape after .view:\", x.shape)\n",
        "        x = self.fc(x)\n",
        "        #print(\"Input shape after fc:\", x.shape)\n",
        "\n",
        "\n",
        "        # print(x.shape)\n",
        "        return x.view(-1)"
      ],
      "metadata": {
        "id": "UiaV4_FG4wbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creation of a Pytorch Lightning module for the MLP architecture\n",
        "\n",
        "class baseline_MLP_PL(pl.LightningModule):\n",
        "  \"\"\"\n",
        "  Pytorch Lignthing class for the baseline transformer\n",
        "  \"\"\"\n",
        "  def __init__(self, num_points, input_dim, num_classes, dropout, patience, factor):\n",
        "    super(baseline_MLP_PL, self).__init__()\n",
        "\n",
        "    self.model = baseline_MLP(\n",
        "    num_points,\n",
        "    input_dim,\n",
        "    num_classes,\n",
        "    dropout\n",
        "  ).to(device)\n",
        "\n",
        "    #self.lr = lr\n",
        "    self.patience = patience\n",
        "    self.factor = factor\n",
        "\n",
        "    self.criterion = nn.BCELoss()\n",
        "\n",
        "    self.accuracy = BinaryAccuracy()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.to(device)\n",
        "    return self.model(x)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters())#, lr=self.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=self.patience, factor=self.factor)\n",
        "    return optimizer\n",
        "\n",
        "  def training_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    outputs = self.model(input)\n",
        "    logits = torch.sigmoid(outputs)\n",
        "    loss = self.criterion(logits, label.float())\n",
        "    self.log(\"train_loss\", loss)\n",
        "    print(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    outputs = self.model(input)\n",
        "    logits = torch.sigmoid(output)\n",
        "\n",
        "    loss = self.criterion(logits, label.float())\n",
        "\n",
        "    acc = self.accuracy(outputs, label)\n",
        "    output_values = {\"val_loss\": loss, \"val_acc\" : acc}\n",
        "    self.log_dict(output_values)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    outputs = self.model(input)\n",
        "    logits = torch.sigmoid(output)\n",
        "    loss = self.criterion(logits, label.float())\n",
        "    acc = self.accuracy(outputs, label)\n",
        "\n",
        "    output_values = {\"test_loss\": loss, \"test_acc\" : acc}\n",
        "    self.log_dict(output_values)\n",
        "    return loss\n",
        "\n",
        "  def predict_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    predicted = self.model(input)\n",
        "    predicted_label = torch.round(predicted)\n",
        "    t_label.append(label.cpu().detach())\n",
        "    p_label.append(predicted_label.cpu().detach())\n",
        "\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "rMjSzTiX5YWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training of the model"
      ],
      "metadata": {
        "id": "rYFXqF_a6M20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, the DataModuleMLP class is instantiated. The Pytorch Module is thus set up for training."
      ],
      "metadata": {
        "id": "6WjZMdVP6r_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MLP_data_module = DataModuleMLP(\n",
        "        global_variables['single_path'],\n",
        "        global_variables['bifurcating_path']\n",
        "    )\n",
        "\n",
        "MLP_data_module.prepare_data()\n",
        "MLP_data_module.setup(stage=\"fit\")\n",
        "train_dataloader = MLP_data_module.train_dataloader()"
      ],
      "metadata": {
        "id": "OJsPLE8E5isZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of the distribution of the data between the two classes\n",
        "check_balancing(MLP_data_module.train_dataset)"
      ],
      "metadata": {
        "id": "hjlrZUv3M74H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input and output dimensions are checked to verify the correctedness of the model."
      ],
      "metadata": {
        "id": "K_8kNphGAWA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check input dimension\n",
        "\n",
        "input = next(iter(train_dataloader))[0].to(device)\n",
        "print(input.shape)"
      ],
      "metadata": {
        "id": "31wZi4F179XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = baseline_MLP_PL(\n",
        "        global_variables['length_data'],\n",
        "        global_variables['dim_input_MLP'],\n",
        "        global_variables['num_classes'],\n",
        "        dropout = global_variables['dropout'],\n",
        "        patience = global_variables['patience'],\n",
        "        factor = global_variables['factor']\n",
        "    )\n",
        "\n",
        "# check output dim\n",
        "output = model(input)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "mq-W6yeZ8PMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "import time\n",
        "mlp_data_module = DataModuleMLP(\n",
        "        global_variables['single_path'],\n",
        "        global_variables['bifurcating_path']\n",
        "    )\n",
        "\n",
        "# model = baseline_MLP_PL(\n",
        "#         global_variables['num_points'],\n",
        "#         global_variables['input_dim_pointnet'],\n",
        "#         global_variables['output_dim'],\n",
        "#         dropout = global_variables['dropout'],\n",
        "#         patience = global_variables['patience'],\n",
        "#         factor = global_variables['factor']\n",
        "#     )\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 5)\n",
        "\n",
        "start_time = time.time()\n",
        "trainer.fit(model, mlp_data_module)\n",
        "end_time = time.time()\n",
        "\n",
        "# Total training time:\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training time: {training_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "zokV2a2pAAMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test:"
      ],
      "metadata": {
        "id": "pIM-IUggBKQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test metrics:\n",
        "trainer.test(model, mlp_data_module)"
      ],
      "metadata": {
        "id": "ytjFcKZmBB0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_label = []\n",
        "p_label = []\n",
        "trainer.predict(model, mlp_data_module)\n",
        "\n",
        "confusion_matrix_display(torch.cat(t_label), torch.cat(p_label))"
      ],
      "metadata": {
        "id": "5PAG9tQ2BWMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check inference time\n"
      ],
      "metadata": {
        "id": "mpI7CUjODAyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ihw2bc0TLnq_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "il3SojG9Navm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geometric Algebra\n",
        "\n",
        "Geometric algebra $G_{3,0,1}$ is used to extend the space $\\mathbb{R}^{3}$ into an equivalent 16-dimensional space that encodes the basic geometric elements (points, planes, lines...) as well as transformations such as rotations, translations and reflections. $G_{3,0,1}$ indicates that the space is characterized by four generators ($e_{0}$, $e_{1}$, $e_{2}$, $e_{3}$). In particular, three of them ($e_{1}$, $e_{2}$, $e_{3}$) satisfy $e_{i}e_{i} = 1$, while the remaining one satisfies $ e_{0}e_{0} = 0 $. TODO: add source\n",
        "\n",
        "The basis components of the multivector associated to the G_{3,0,1} algebra are obtained by considering every possible multiplicative combination of the basis elements. Elements of different grade are thus obtained:\n",
        "\n",
        "Grade 0 ($1$): scalars in the G.A. \\\\\n",
        "Grade 1 ($e_{0}$, $e_{i}$): vectors in the G.A. \\\\\n",
        "Grade 2 ($e_{0i}$, $e_{ij}$); bivectors in the G.A. \\\\\n",
        "Grade 3 ($e_{0ij}$, $e_{ijk}$): trivectors in the G.A. \\\\\n",
        "Grade 4 ($e_{0123}$): pseudoscalars in the G.A. \\\\\n",
        "\n",
        "The multivector representation associated to the Geometric Algebra G_{3,0,1} will thus be composed of a total of 16 elements.\n",
        "\n",
        "Scalars will be represented by grade 0 elements, planes by grade 1 elements, lines by grade 2 elements, points by grade 3 elements and pseudoscalar by grade 4 elements."
      ],
      "metadata": {
        "id": "r5aiqBKACZqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of the embeddings\n",
        "Each sample of the dataset represents a portion of an artery and is characterized by a set of 3D points (pos), a set of plane faces each delimited by 3 points (faces), a set of wall sheer stress vectors (wss), a set of inlet indeces (inlet_idcs), and a set of pressure values (pressure).\n",
        "The data is encoded using the definitions provided in arcicle TODO cite, and shown below. Before the embedding procedure, the data is standardized. \\\\\n",
        "NOTE: The inlet indices are a set of natural numbers that identify the indices of the 3D points that lie on the entrance border of the artery. For the task of classifying the arteries, they are not as rich in information as the other components of the data samples. Thus, the multivectors corresponding to the inlet indeces are not included in the total concatenated embedding of the samples. Nevertheless, the definition of their embedding is provided for the sake of completeness.\n",
        "\n",
        "<center>\n",
        "\n",
        "![Baseline](https://drive.google.com/uc?export=download&id=1f7fpn1U784RmHogDEwdFrd8ptaMhVS1C)\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "6QEYnLxGKS6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_pos_mv_16(pos):\n",
        "    \"\"\"\n",
        "    Embeds the pos torch tensor as a 16-dimensional G_{3,0,1} multivector\n",
        "\n",
        "    Args:\n",
        "        pos (torch.Tensor): tensor of input points with shape (n_elements, 3)\n",
        "\n",
        "    Returns:\n",
        "        pos_mv torch.Tensor: tensor of multivectors of dimension 16 with shape (1, n_elements, 1, 16)\n",
        "    \"\"\"\n",
        "    # Positions in Euclidean geometry can be embedded as points in G_{3,0,1} algebra\n",
        "\n",
        "    # Get the number of points and the dimensionality\n",
        "    n_elements = pos.shape[0]\n",
        "    dim = pos.shape[1]\n",
        "\n",
        "    # Create multivector tensor\n",
        "    multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "\n",
        "    multivector[:, 14] = 1 # homogeneous component, e_{123}\n",
        "    multivector[:, 11] = pos[:, 0] # x, e_{023}\n",
        "    multivector[:, 12] = pos[:, 1] # y, e_{013}\n",
        "    multivector[:, 13] = pos[:, 2] # z, e_{012}\n",
        "\n",
        "    pos_mv = multivector.reshape(1,n_elements,1,global_variables['dim_GA'])\n",
        "\n",
        "    return pos_mv"
      ],
      "metadata": {
        "id": "_rOjz5XGE1FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_face_mv_16(face):\n",
        "    \"\"\"\n",
        "    Embeds the face torch tensor as a 16-dimensional G_{3,0,1} multivector\n",
        "\n",
        "    Input:\n",
        "        face torch.Tensor of size (n_elements, 3)\n",
        "    Output:\n",
        "        mv torch.Tensor of size (1, n_elements, 1, 16)\n",
        "    \"\"\"\n",
        "\n",
        "    # An oriented surface in Euclidean geometry characterized by\n",
        "    #   the normal vector n to the surface itself can be embedded as an oriented\n",
        "    #   plane in G_{3,0,1} algebra\n",
        "\n",
        "\n",
        "    # Get the number of points and the dimensionality of the space\n",
        "    n_elements = face.shape[0]\n",
        "    dim = face.shape[1]\n",
        "\n",
        "    # Create multivector tensor\n",
        "    multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "\n",
        "    multivector[:, 2] = face[:, 0] # e_{1}\n",
        "    multivector[:, 3] = face[:, 1] # e_{2}\n",
        "    multivector[:, 4] = face[:, 2] # e_{3}\n",
        "\n",
        "    face_mv = multivector.reshape(1,n_elements,1,global_variables['dim_GA'])\n",
        "\n",
        "    return face_mv"
      ],
      "metadata": {
        "id": "nFhi2My_E2Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_wss_mv_16(wss):\n",
        "    \"\"\"\n",
        "    Embeds the wss vectors as a 16 dimensional G_{3,0,1} multivector\n",
        "    Input:\n",
        "      wss torch.Tensor of size (n_elements, 3)\n",
        "    Output:\n",
        "      wss_mv torch.Tensor of size (1, n_elements, 1, 16)\n",
        "    \"\"\"\n",
        "\n",
        "    # A 3D vector in the Euclidean space can be embedded as a translation in G_{3,0,1} algebra\n",
        "\n",
        "    n_elements = wss.shape[0]\n",
        "    dim = wss.shape[1]\n",
        "\n",
        "    multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "\n",
        "    multivector[:, 0] = 1\n",
        "    multivector[:, 5] = 0.5*wss[:, 0] # e_{01}\n",
        "    multivector[:, 6] = 0.5*wss[:, 1] # e_{02}\n",
        "    multivector[:, 7] = 0.5*wss[:, 2] # e_{03}\n",
        "\n",
        "    wss_mv = multivector.reshape(1,n_elements,1,global_variables['dim_GA'])\n",
        "\n",
        "    return wss_mv"
      ],
      "metadata": {
        "id": "pUe6BOxLFJrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_inlet_mv_16(inlet):\n",
        "    \"\"\"\n",
        "    Embeds the inlet torch tensor as a 16 dimensional G_{3,0,1} multivector\n",
        "    Input:\n",
        "        inlet torch.Tensor of size (n_elements, 1)\n",
        "    Output:\n",
        "        inlet_mv torch.Tensor of size (1, n_elements, 1, 16)\n",
        "    \"\"\"\n",
        "    # Inlet indexes can be embedded as scalars in G_{3,0,1} algebra\n",
        "\n",
        "    n_elements = inlet.shape[0]\n",
        "\n",
        "    multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "    multivector[:, 0] = inlet[:]\n",
        "\n",
        "    inlet_mv = multivector.reshape(1, n_elements, 1, global_variables['dim_GA'])\n",
        "\n",
        "    return inlet_mv"
      ],
      "metadata": {
        "id": "7lRxhBE5FPPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_pressure_mv_16(pressure):\n",
        "  \"\"\"\n",
        "  Embeds the pressure torch tensor as a 16-dimensional G_{3,0,1} multivector\n",
        "  Input:\n",
        "    pressure torch.Tensor of size (n_elements, 1)\n",
        "  Output:\n",
        "    pressure_mv torch.Tensor of size (1, n_elements, 1, 16)\n",
        "  \"\"\"\n",
        "\n",
        "  n_elements = pressure.shape[0]\n",
        "\n",
        "  # Initialize the multivector\n",
        "  multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "\n",
        "  multivector[:,0] = pressure[:]\n",
        "  pressure_mv = multivector.reshape(1, n_elements, 1, global_variables['dim_GA'])\n",
        "\n",
        "  return pressure_mv"
      ],
      "metadata": {
        "id": "03FIQj20FXPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_complete_mv_16(sample_path):\n",
        "  \"\"\"\n",
        "  Embeds the artery sample into a concatenation of 4 16-dimensional multivectors in G_{3,0,1}.\n",
        "  Each of the 4 multivectors embeds a different feature of the artery: pos, face, wss, pressure\n",
        "  The data is standardized before the embedding\n",
        "  Input:\n",
        "    sample_path: path to the artery sample saved in hdf5 format\n",
        "  Output:\n",
        "    sample_embedding: torch.Tensor of size (1, length_data, 4, 16)\n",
        "        where length_data is the number of points in the samples considered for the embedding\n",
        "  \"\"\"\n",
        "\n",
        "  with h5py.File(sample_path, 'r') as f:\n",
        "    # extract torch tensor for pos\n",
        "    pos_data = f['pos'][:global_variables['length_data']]\n",
        "    pos_torch = torch.tensor(pos_data[:])\n",
        "    pos_torch_norm = (pos_torch - torch.mean(pos_torch)) / torch.std(pos_torch)\n",
        "\n",
        "    # extract torch tensor for face\n",
        "    face_data = f['face'][:global_variables['length_data']]\n",
        "    face_torch = torch.tensor(face_data[:])\n",
        "\n",
        "    # extract torch tensor for wss\n",
        "    wss_data = f['wss'][:global_variables['length_data']]\n",
        "    wss_torch = torch.tensor(wss_data[:])\n",
        "    wss_torch_norm = (wss_torch - torch.mean(wss_torch)) / torch.std(wss_torch)\n",
        "\n",
        "    # extract torch tensor for pressure\n",
        "    pressure_data = f['pressure'][:global_variables['length_data']]\n",
        "    pressure_torch = torch.tensor(pressure_data[:])\n",
        "    pressure_torch_norm = (pressure_torch - torch.mean(pressure_torch)) / torch.std(pressure_torch)\n",
        "\n",
        "  # Get the multivector embeddings for each torch tensor\n",
        "  pos_mv_16 = embed_pos_mv_16(pos_torch_norm)\n",
        "  face_mv_16 = embed_face_mv_16(face_torch)\n",
        "  wss_mv_16 = embed_wss_mv_16(wss_torch_norm)\n",
        "  pressure_mv_16 = embed_pressure_mv_16(pressure_torch_norm)\n",
        "\n",
        "  sample_embedding = torch.cat(\n",
        "      [pos_mv_16, face_mv_16, wss_mv_16, pressure_mv_16], dim = 2)\n",
        "\n",
        "  return sample_embedding"
      ],
      "metadata": {
        "id": "ll-POLsqFh6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use of embed_complete_mv_16\n",
        "\n",
        "sample_path = \"/content/GATr_Deep_Learning_Project/single/sample_0000.hdf5\"\n",
        "sample_embedding = embed_complete_mv_16(sample_path)\n",
        "print(sample_embedding.shape)"
      ],
      "metadata": {
        "id": "XhspGp72FoxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geometric Algebra Transformations\n",
        "\n",
        "Basic transformation operations are defined using the definitions provided in article TODO cite. The defined transformations are:\n",
        "\n",
        "\n",
        "*   Reflection with respect to a plane;\n",
        "*   Translation;\n",
        "*   Reflection with respect to a point;\n",
        "*   Rotation identified by a quaternion.\n"
      ],
      "metadata": {
        "id": "VEtqNCVQGR3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_plane_reflection_mv_16(normal, d):\n",
        "  \"\"\"\n",
        "  Embeds a plane reflection transformation given a normal vector and an origin shift\n",
        "  as a 16-dimensional multivector in G_{3,0,1}\n",
        "  Input:\n",
        "    normal: torch.Tensor (1, 3) normal to the plane\n",
        "    d: origin shift\n",
        "  Output:\n",
        "    pr_mv_16: torch.Tensor multivector of size (1,1,1,16) representing the plane reflection\n",
        "    inv_pr_mv_16: torch.Tensor multivector of size (1,1,1,16) representing the inverse plane reflection\n",
        "  \"\"\"\n",
        "  # Initialize the multivector\n",
        "  plane_reflection_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  plane_reflection_mv_16[0,1] = d\n",
        "  plane_reflection_mv_16[0,2] = normal[0]\n",
        "  plane_reflection_mv_16[0,3] = normal[1]\n",
        "  plane_reflection_mv_16[0,4] = normal[2]\n",
        "\n",
        "  pr_mv_16 = plane_reflection_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  #Define the inverse plane reflection\n",
        "  inv_plane_reflection_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  inverse_shift = -d\n",
        "\n",
        "  inv_plane_reflection_mv_16[0,1] = inverse_shift\n",
        "  inv_plane_reflection_mv_16[0,2] = normal[0]\n",
        "  inv_plane_reflection_mv_16[0,3] = normal[1]\n",
        "  inv_plane_reflection_mv_16[0,4] = normal[2]\n",
        "\n",
        "  inv_pr_mv_16 = inv_plane_reflection_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  return pr_mv_16, inv_pr_mv_16"
      ],
      "metadata": {
        "id": "zJ8m35gFGa8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_translation_mv_16(t):\n",
        "  \"\"\"\n",
        "  Embeds a translation by a vector t in R^{3} as a 16-dimensional multivector in G_{3,0,1}\n",
        "  Input:\n",
        "    t: torch.Tensor of size (1, 3) representing a translation in the 3D space\n",
        "  Output:\n",
        "    tr_mv_16: torch.Tensor multivector of size (1,1,1,16) representing the translation\n",
        "    inv_tr_mv_16:\n",
        "  \"\"\"\n",
        "  # Initialize the multivector\n",
        "  translation_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  translation_mv_16[0,0] = 1 # homogeneous component\n",
        "  translation_mv_16[0,5] = 0.5*t[0]\n",
        "  translation_mv_16[0,6] = 0.5*t[1]\n",
        "  translation_mv_16[0,7] = 0.5*t[2]\n",
        "\n",
        "  tr_mv_16 = translation_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  # define the inverse translation multivector\n",
        "  # the transformation will be characterized by opposite translation vector: t -> -t\n",
        "  inv_translation_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  inv_t = -t\n",
        "\n",
        "  inv_translation_mv_16[0,0] = 1 # homogeneous component\n",
        "  inv_translation_mv_16[0,5] = 0.5*inv_t[0]\n",
        "  inv_translation_mv_16[0,6] = 0.5*inv_t[1]\n",
        "  inv_translation_mv_16[0,7] = 0.5*inv_t[2]\n",
        "\n",
        "  inv_tr_mv_16 = inv_translation_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  return tr_mv_16, inv_tr_mv_16"
      ],
      "metadata": {
        "id": "C9Vw6dGZGehD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_point_reflection_mv(p):\n",
        "  \"\"\"\n",
        "  Embeds a reflection with respect to a point p in R^{3} as a 16-dimensional multivector in G_{3,0,1}\n",
        "  Input:\n",
        "    p: torch.Tensor of size (1,3) representing a point in 3D\n",
        "  Output:\n",
        "    pt_ref_mv_16: torch.Tensor of size (1,1,1,16) representing the point reflection\n",
        "    inv_pt_ref_mv_16: torch.Tensor representing the inverse point reflection\n",
        "  \"\"\"\n",
        "  # Initialize the multivector\n",
        "  point_reflection_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  point_reflection_mv_16[0,11] = p[0]\n",
        "  point_reflection_mv_16[0,12] = p[1]\n",
        "  point_reflection_mv_16[0,13] = p[2]\n",
        "  point_reflection_mv_16[0,14] = 1\n",
        "\n",
        "  # Reshape to match the shape of the other multivectors\n",
        "  pt_ref_mv_16 = point_reflection_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  # Definition of the multivector associated to the inverse operation\n",
        "  # It is a reflection with respect to the opposite point\n",
        "\n",
        "  inv_p = -p\n",
        "\n",
        "  inv_point_reflection_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  inv_point_reflection_mv_16[0,11] = inv_p[0]\n",
        "  inv_point_reflection_mv_16[0,12] = inv_p[1]\n",
        "  inv_point_reflection_mv_16[0,13] = inv_p[2]\n",
        "  inv_point_reflection_mv_16[0,14] = 1\n",
        "\n",
        "  inv_pt_ref_mv_16 = inv_point_reflection_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  return pt_ref_mv_16, inv_pt_ref_mv_16"
      ],
      "metadata": {
        "id": "2_7iiqonGjm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_quaternion_rotation_mv_16(rot_axis, alpha):\n",
        "  \"\"\"\n",
        "  Embeds a rotation defined by a quaterion through the axis angle rotation representation\n",
        "  Input:\n",
        "    rot_axis: list of size 1x3 representing the axis of the rotation [r1,r2,r3]\n",
        "    alpha: float representing the angle of the rotation\n",
        "  Output:\n",
        "    quat_rot_mv_16: torch.Tensor of size (1,1,1,16) representing a rotation quaternion rotation\n",
        "    inv_quat_rot_mv_16: torch.Tensor of size (1,1,1,16) representing a rotation quaternion rotation\n",
        "  \"\"\"\n",
        "  quaternion = Quaternion(axis=rot_axis, angle=alpha)\n",
        "\n",
        "  # Initialize the multivector\n",
        "  quaternion_rotation_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  quaternion_rotation_mv_16[0, 0] = quaternion.w\n",
        "  quaternion_rotation_mv_16[0, 8] = quaternion.x\n",
        "  quaternion_rotation_mv_16[0, 9] = quaternion.y\n",
        "  quaternion_rotation_mv_16[0, 10] = quaternion.z\n",
        "\n",
        "  quat_rot_mv_16 = quaternion_rotation_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  # Definition of the inverse rotation\n",
        "  # A new quaternion generated by the same axis and opposite angle of rotation is generated\n",
        "\n",
        "  inv_alpha = -alpha\n",
        "\n",
        "  inv_quaternion = Quaternion(axis=rot_axis, angle=inv_alpha)\n",
        "\n",
        "  inv_quaternion_rotation_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  inv_quaternion_rotation_mv_16[0, 0] = inv_quaternion.w\n",
        "  inv_quaternion_rotation_mv_16[0, 8] = inv_quaternion.x\n",
        "  inv_quaternion_rotation_mv_16[0, 9] = inv_quaternion.y\n",
        "  inv_quaternion_rotation_mv_16[0, 10] = inv_quaternion.z\n",
        "\n",
        "  inv_quat_rot_mv_16 = inv_quaternion_rotation_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  return quat_rot_mv_16, inv_quat_rot_mv_16"
      ],
      "metadata": {
        "id": "2drWMshsGoFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Blades\n",
        "\n",
        "The projection of a multivector $x$ in the subspace of grade $k$ is denoted as the $\\bf{blade}$ of grade $k$ of the multivector. Blades are used to define an equilinear map $\\phi$ between two elements of the multivector space:\n",
        "\n",
        "$$ \\phi(x) = \\sum_{k=0}^{d+1}w_{k}<x>_{k} + \\sum_{k=0}^{d}v_{k} e_{0}<x>_{k}$$\n",
        "\n",
        "Where $d$ is the spatial dimensions of the algebra $G_{d,0,1}$,  $w_{k}$ is the coefficient associated to the blade of grade $k$ of the multivector, $v_{k}$ is the coefficient associated to the blade of grade $k$ multiplied by base element $e_{0}$.\n",
        "\n",
        "In the definitions below, $w_{blade}$ denotes the blade of grade $k$ ($<x>_{k}$) and $v_{blade}$ denotes the blade of grade $e_{0}$ multiplied by the blade of grade $k$ ($e_{0}<x>_{k}$)."
      ],
      "metadata": {
        "id": "nb1PL3wCAEFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4f62Xq0EWOgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_blades(mv, layout):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "      mv: torch.Tensor multivector of size [1, global_variables['dim_GA]]\n",
        "      layout: clifford layout of the geometric algebra\n",
        "\n",
        "    Output:\n",
        "      blades (torch.Tensor):\n",
        "            - w_{k}: blade projections of mv\n",
        "            - v_{k}: geometric product between e_0 and the blade projections w_{k}\n",
        "    \"\"\"\n",
        "\n",
        "    # mv: torch.Tensor [1, 16]\n",
        "    cf_mv = layout.MultiVector(mv.numpy())\n",
        "\n",
        "    w_blade_array = []\n",
        "    v_blade_array = []\n",
        "    blade_array = []\n",
        "\n",
        "    grades = len(cf_mv.grades())\n",
        "\n",
        "    for grade in range(grades):\n",
        "        # elements w_{k} (5 elements)\n",
        "        cf_w_blade = cf_mv(grade)  # mv in clifford\n",
        "        coeffs = list(cf_w_blade.value)\n",
        "        blade_torch = torch.tensor(coeffs)\n",
        "        w_blade_array.append(blade_torch)\n",
        "\n",
        "    for grade in range(grades-1):  # end at num_blades-1\n",
        "        # elements v_k (4 elements)\n",
        "        cf_blade = cf_mv(grade)\n",
        "        cf_v_blade = e0^cf_blade  # Use the geometric product to extract v-blades\n",
        "        coeffs = list(cf_v_blade.value)\n",
        "        blade_torch = torch.tensor(coeffs)\n",
        "        v_blade_array.append(blade_torch)\n",
        "\n",
        "    blades = torch.stack(w_blade_array + v_blade_array)\n",
        "\n",
        "    return blades"
      ],
      "metadata": {
        "id": "wxy4JuoEGgQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blade_matrices(blades):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    blades (torch.Tensor): blade projection of a multivector\n",
        "          containing torch.Tensors of type w_{k} and v_{k}\n",
        "\n",
        "  Output:\n",
        "    matrices_stack (torch.Tensor): stack of matrix operators that represent the blades\n",
        "  \"\"\"\n",
        "\n",
        "  matrices = []\n",
        "  for _, blade in enumerate(blades):\n",
        "\n",
        "    matrix = torch.zeros((global_variables['dim_GA'], global_variables['dim_GA']))\n",
        "    for i, element in enumerate(blade):\n",
        "      if element.int() != 0:\n",
        "        matrix[i][element.int()-1] = 1\n",
        "    matrices.append(matrix)\n",
        "\n",
        "    matrices_stack = torch.stack(matrices)\n",
        "\n",
        "  return matrices_stack\n"
      ],
      "metadata": {
        "id": "E51Oii5lfbd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Operations between multivectors\n",
        "The inner, outer, and geometric product between multivectors are defined by applying the Einstein coefficients formalism on torch tensors."
      ],
      "metadata": {
        "id": "4GKjApOK4bTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate clifford G_{3,0,1} algebra\n",
        "layout, blades = cf.Cl(p=3, q=0, r=1, firstIdx=0)\n",
        "locals().update(blades)\n",
        "\n",
        "print('PGA blades: ', blades)\n",
        "print('PGA layout: ', layout)"
      ],
      "metadata": {
        "id": "mSOsxD4K6S20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask_product():\n",
        "\n",
        "    \"\"\"\n",
        "    Function that generates a multivector mask that contains 0 if the corresponding multivector blade contains e0, 1 otherwise\n",
        "    Output:\n",
        "      mask (torch.Tensor)\n",
        "    \"\"\"\n",
        "\n",
        "    mv = torch.ones(global_variables['dim_GA'])\n",
        "    cf_mv = layout.MultiVector(mv.numpy())\n",
        "    prod = e0^cf_mv\n",
        "    coeffs = list(prod.value)\n",
        "    mask_complement = torch.Tensor(coeffs)\n",
        "    mask = 1- mask_complement\n",
        "\n",
        "    return mask"
      ],
      "metadata": {
        "id": "y2Mtr9N0LlYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: add reference for these three functions below inner, geometric, outer product\n",
        "def inner_product(x, y):\n",
        "    \"\"\"\n",
        "    Computes the inner product of multivectors f(x,y) = <x, y> = <~x y>_0.\n",
        "\n",
        "    Sums over the 16 multivector dimensions.\n",
        "\n",
        "    Equal to `geometric_product(reverse(x), y)[..., [0]]` (but faster).\n",
        "\n",
        "    Input:\n",
        "      x : torch.Tensor with shape (..., 16) or (..., channels, 16)\n",
        "        First input multivector. Batch dimensions must be broadcastable between x and y.\n",
        "      y : torch.Tensor with shape (..., 16) or (..., channels, 16)\n",
        "        Second input multivector. Batch dimensions must be broadcastable between x and y.\n",
        "\n",
        "    Returns:\n",
        "    outputs : torch.Tensor with shape (..., 1)\n",
        "        Result. Batch dimensions are result of broadcasting between x and y.\n",
        "    \"\"\"\n",
        "\n",
        "    guidance = torch.load(global_variables['geometric_guidance']).to_dense()\n",
        "\n",
        "    reversal_index = torch.ones(16)[5:15] = -1\n",
        "\n",
        "    inner_product_mask = (torch.diag(guidance[0]) * reversal_index).bool()\n",
        "\n",
        "    selector = torch.arange(16)[inner_product_mask]\n",
        "\n",
        "    x = x[..., selector]\n",
        "    y = y[..., selector]\n",
        "\n",
        "    outputs = torch.einsum(\n",
        "        \"... i, ... i -> ...\",\n",
        "        x,\n",
        "        y\n",
        "    )\n",
        "\n",
        "    # We want the output to have shape (..., 1)\n",
        "    outputs = outputs.unsqueeze(-1)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "BVxtzI8z45df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outer_product(x, y):\n",
        "    \"\"\"\n",
        "    Computes the outer product `f(x,y) = x ^ y`.\n",
        "\n",
        "    Inputs\n",
        "    x : torch.Tensor with shape (..., 16)\n",
        "        First input multivector. Batch dimensions must be broadcastable between x and y.\n",
        "    y : torch.Tensor with shape (..., 16)\n",
        "        Second input multivector. Batch dimensions must be broadcastable between x and y.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    outputs : torch.Tensor with shape (..., 16)\n",
        "        Result. Batch dimensions are result of broadcasting between x, y, and coeffs.\n",
        "    \"\"\"\n",
        "\n",
        "    guidance = torch.load(global_variables['outer_guidance']).to_dense()\n",
        "\n",
        "    outputs = torch.einsum(\n",
        "        \"i j k, ... j, ... k -> ... i\",\n",
        "        guidance.float().to(device),\n",
        "        x,\n",
        "        y\n",
        "    )\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "bWWNX7VS5AB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def geometric_product(x, y):\n",
        "    \"\"\"Computes the geometric product f(x,y) = xy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : torch.Tensor with shape (..., 16)\n",
        "        First input multivector. Batch dimensions must be broadcastable between x and y.\n",
        "    y : torch.Tensor with shape (..., 16)\n",
        "        Second input multivector. Batch dimensions must be broadcastable between x and y.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    outputs : torch.Tensor with shape (..., 16)\n",
        "        Result. Batch dimensions are result of broadcasting between x, y, and coeffs.\n",
        "    \"\"\"\n",
        "\n",
        "    # Select kernel on correct device\n",
        "    guidance = torch.load(global_variables['geometric_guidance']).to_dense()\n",
        "\n",
        "    # Compute geometric product\n",
        "    outputs =  torch.einsum(\n",
        "        \"i j k, ... j, ... k -> ... i\",\n",
        "        guidance.float().to(device),\n",
        "        x,\n",
        "        y\n",
        "    )\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "ffSdcpOs5DzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sandwich_product(mv, u, u_inv):\n",
        "  \"\"\"\n",
        "  Computes the sandwich product between a multivector mv and a vector operator u\n",
        "  Inputs:\n",
        "    mv (torch.Tensor): multivector\n",
        "    u (torch.Tensor): multivector operator\n",
        "    u_inv (torch.Tensor): inverse of u\n",
        "\n",
        "  Output:\n",
        "    res (torch.Tensor): result of the sandwich product\n",
        "  \"\"\"\n",
        "\n",
        "  res_temp = geometric_product(u, mv)\n",
        "  res = geometric_product(res_temp, u_inv)\n",
        "\n",
        "  return res"
      ],
      "metadata": {
        "id": "alr--KXWmIKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Join operator\n",
        "The join operation between two multivectors is defined as\n",
        "$$ JOIN(x, y) = (x^{*} \\wedge y^{*})^{*}, $$ where $\\wedge$ denotes the outer product between multivectors and ${(\\cdot)}^{*}$ denotes the dual of a multivector. \\\\"
      ],
      "metadata": {
        "id": "W3GQWWH49-96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dualize_mv(mv):\n",
        "\n",
        "  '''\n",
        "  Returns the dual of multivector mv\n",
        "\n",
        "  Input:\n",
        "    mv: torch.Tensor of size [1, global_variables['dim_GA']]\n",
        "\n",
        "  Output:\n",
        "    dualized_mv: torch.Tensor of size [1, global_variables['dim_GA']], dual multivector of mv\n",
        "  '''\n",
        "\n",
        "  mv_size = global_variables['dim_GA']\n",
        "  dualization_map = torch.zeros([mv_size, mv_size])\n",
        "  for i in range(mv_size):\n",
        "    dualization_map[i, mv_size-1-i] = 1 # matrix with 1 on the antidiagonal, 0 elsewhere\n",
        "\n",
        "  dualized_mv = torch.matmul(mv, dualization_map.to(device))\n",
        "\n",
        "  return dualized_mv"
      ],
      "metadata": {
        "id": "U_IHWUuXV8P8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# join operation\n",
        "def join_operation(mv_1, mv_2):\n",
        "  '''\n",
        "  Performs the join operation between two multivectors\n",
        "\n",
        "  Input:\n",
        "    mv_1: torch.Tensor of size [1, global_variables['dim_GA']]\n",
        "    mv_2: torch.Tensor of size [1, global_variables['dim_GA']]\n",
        "\n",
        "  Output:\n",
        "    joined_mv: torch.Tensor of size [1, global_variables['dim_GA']], result of the join operation\n",
        "  '''\n",
        "\n",
        "  mv_1_dual = dualize_mv(mv_1)\n",
        "  mv_2_dual = dualize_mv(mv_2)\n",
        "  outer_prod = outer_product(mv_1_dual, mv_2_dual)\n",
        "  joined_mv = dualize_mv(outer_prod)\n",
        "\n",
        "  return joined_mv\n"
      ],
      "metadata": {
        "id": "cr3l69xzV-ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of use of the functions above:\n",
        "# TODO: questo si potrebbe togliere.\n",
        "\n",
        "mv_1 = torch.Tensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]).to(device)\n",
        "mv_2 = torch.Tensor([16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1]).to(device)\n",
        "\n",
        "geometric_prod_mv = geometric_product(mv_1,mv_2)\n",
        "print('multivector 1: ', mv_1)\n",
        "print('multivector 2: ', mv_2)\n",
        "print('geometric product mv_1*mv_2: ', geometric_prod_mv)"
      ],
      "metadata": {
        "id": "zHixl4sB7lGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Module"
      ],
      "metadata": {
        "id": "ioUmoN9-Vy7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "  \"\"\"\n",
        "  Class DataModule used for handling data loading, preparation, and splitting\n",
        "  into training, validation, and test sets.\n",
        "  \"\"\"\n",
        "  def __init__(self, path_single, path_bifurcating):\n",
        "\n",
        "    super(DataModule,self).__init__()\n",
        "\n",
        "    self.single_data_path = path_single\n",
        "    self.bifurcating_data_path = path_bifurcating\n",
        "    self.dataset = None\n",
        "\n",
        "  def prepare_data(self):\n",
        "    \"\"\"\n",
        "    This method is used for loading and shuffling data\n",
        "    \"\"\"\n",
        "    single_dataset, label_single = self.load_data(self.single_data_path,  bifurcating=False)\n",
        "    bifurcating_dataset, label_bifurcating = self.load_data(self.bifurcating_data_path,  bifurcating=True)\n",
        "    indices = torch.randperm(label_single.shape[0] + label_bifurcating.shape[0])\n",
        "\n",
        "    self.dataset = self.shuffle_and_combine_datasets(single_dataset, bifurcating_dataset, indices)\n",
        "    self.label = self.shuffle_and_combine_datasets(label_single, label_bifurcating, indices)\n",
        "\n",
        "  def setup(self, stage=None):\n",
        "    \"\"\"\n",
        "    This method is used for setting up the datasets for training, validation, and testing.\n",
        "\n",
        "    Inputs:\n",
        "      stage (str, optional): Stage of the training process (fit, test). Default is None.\n",
        "    \"\"\"\n",
        "    train, validation, test , predict = self.split_dataset(list(zip(self.dataset, self.label)))\n",
        "\n",
        "    if stage == \"fit\" or stage is None:\n",
        "      self.train_dataset = train\n",
        "      self.validation_dataset = validation\n",
        "\n",
        "    if stage == \"test\" or stage is None:\n",
        "      self.test_dataset = test\n",
        "\n",
        "    if stage == \"predict\" or stage is None:\n",
        "      self.predict_dataset = predict\n",
        "\n",
        "  def load_data(self, path, bifurcating=False):\n",
        "    \"\"\"\n",
        "    This method is used for loading the data and assigning a label to each sample.\n",
        "\n",
        "    Inputs:\n",
        "      path (str): Path to the dataset.\n",
        "      bifurcating (bool):\n",
        "\n",
        "    Output:\n",
        "      data (torch.Tensor): Loaded data.\n",
        "      label (torch.Tensor): Corresponding labels.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    for file in os.listdir(path):\n",
        "        data.append(embed_complete_mv_16(path + file))\n",
        "\n",
        "    label = torch.ones(len(data)) if bifurcating else torch.zeros(len(data))\n",
        "    data = torch.stack(data).squeeze()\n",
        "\n",
        "    return data , label\n",
        "\n",
        "  def shuffle_and_combine_datasets(self, dataset1, dataset2, indices):\n",
        "      \"\"\"\n",
        "      This method is used to combine and shuffle the datasets\n",
        "      Input:\n",
        "        dataset1 (torch.Tensor): first dataset\n",
        "        dataset2 (torch.Tensor): second dataset\n",
        "        indices (torch.Tensor): indices used for shuffling\n",
        "\n",
        "      Output:\n",
        "        shuffled_dataset (torch.Tensor): shuffled dataset\n",
        "      \"\"\"\n",
        "      combined_dataset = ConcatDataset([dataset1, dataset2])\n",
        "      shuffled_dataset = Subset(combined_dataset, indices)\n",
        "\n",
        "      return shuffled_dataset\n",
        "\n",
        "  def split_dataset(self, dataset, train_ratio=0.7, validation_ratio=0.1, test_ratio=0.1, prediction_ratio = 0.1):\n",
        "      \"\"\"\n",
        "      This method is used to split the dataset into training, validation and test set\n",
        "      Inputs:\n",
        "        dataset (torch.Tensor): entire dataset\n",
        "        train_ratio (float)\n",
        "        validation_ratio (float)\n",
        "        test_ratio (float)\n",
        "\n",
        "      Output:\n",
        "        train_dataset, validation_dataset, test_dataset (torch.Tensor)\n",
        "      \"\"\"\n",
        "\n",
        "      total_size = len(dataset)\n",
        "      train_size = int(total_size * train_ratio)\n",
        "      validation_size = int(total_size * validation_ratio)\n",
        "      test_size = int(total_size * test_ratio)\n",
        "      pred_size = total_size - train_size - validation_size - test_size\n",
        "\n",
        "      train_dataset, validation_dataset, test_dataset , predict_dataset = random_split(dataset, [train_size, validation_size, test_size, pred_size])\n",
        "\n",
        "      return train_dataset, validation_dataset, test_dataset, predict_dataset\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      \"\"\"\n",
        "      This method returns the train dataloader\n",
        "      \"\"\"\n",
        "      return DataLoader(\n",
        "          self.train_dataset,\n",
        "          shuffle = True,\n",
        "          batch_size = global_variables['batch_size'],\n",
        "          num_workers = global_variables['num_workers']\n",
        "        )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "      \"\"\"\n",
        "      This method returns the validation dataloader\n",
        "      \"\"\"\n",
        "      return DataLoader(\n",
        "          self.validation_dataset,\n",
        "          shuffle = False,\n",
        "          batch_size = global_variables['batch_size'],\n",
        "          num_workers = global_variables['num_workers']\n",
        "        )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "      \"\"\"\n",
        "      This method returns the test dataloader\n",
        "      \"\"\"\n",
        "      return DataLoader(\n",
        "          self.test_dataset,\n",
        "          shuffle = False,\n",
        "          batch_size = global_variables['batch_size'],\n",
        "          num_workers = global_variables['num_workers']\n",
        "        )\n",
        "\n",
        "  def predict_dataloader(self):\n",
        "      \"\"\"\n",
        "      This method returns the predict dataloader\n",
        "      \"\"\"\n",
        "      return DataLoader(\n",
        "            self.predict_dataset,\n",
        "            shuffle = False,\n",
        "            batch_size = global_variables['batch_size'],\n",
        "            num_workers = global_variables['num_workers']\n",
        "          )\n",
        "\n",
        "  def train_dataset(self):\n",
        "    \"\"\"\n",
        "    This method returns the training dataset\n",
        "    \"\"\"\n",
        "    return self.train_dataset\n",
        "\n",
        "  def val_dataset(self):\n",
        "    \"\"\"\n",
        "    This method returns the validation dataset\n",
        "    \"\"\"\n",
        "    return self.val_dataset\n",
        "\n",
        "  def test_dataset(self):\n",
        "    \"\"\"\n",
        "    This method returns the test dataset\n",
        "    \"\"\"\n",
        "    return self.test_dataset\n",
        "\n",
        "  def predict_dataset(self):\n",
        "    \"\"\"\n",
        "    This method returns the predict dataset\n",
        "    \"\"\"\n",
        "    return self.predict_dataset"
      ],
      "metadata": {
        "id": "vSkUkYzetikG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"# TODO: queste sono prove o servono per il codice?\n",
        "data_module_prove = DataModule(global_variables['single_path'], global_variables['bifurcating_path'])\n",
        "\n",
        "data_module_prove.prepare_data()\n",
        "data_module_prove.setup(stage=\"fit\")\n",
        "train_dataloader = data_module_prove.train_dataloader()\"\"\""
      ],
      "metadata": {
        "id": "5KWJxgI_N30b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Transformer\n",
        "\n",
        "TODO: qui bisognerebbe spiegare un po' le scelte fatte: perche' questo transformer, perche' questo embedding...\n",
        "<center>\n",
        "\n",
        "![Baseline](https://drive.google.com/uc?export=download&id=1gg8ec3XNFPuOmF4RM_eJpmflVb9NDwFq)\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "D3R1BAx-EKcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  \"\"\"\n",
        "  Multi-head attention module for the baseline transformer\n",
        "  \"\"\"\n",
        "  def __init__(self, hidden_dim, num_heads, dropout=0.1):\n",
        "      super(MultiHeadAttention, self).__init__()\n",
        "      assert hidden_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "      self.hidden_dim = hidden_dim\n",
        "      self.num_heads = num_heads\n",
        "      self.head_dim = hidden_dim // num_heads\n",
        "\n",
        "      self.query = nn.Linear(self.head_dim, self.head_dim)\n",
        "      self.key = nn.Linear(self.head_dim, self.head_dim)\n",
        "      self.value = nn.Linear(self.head_dim, self.head_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "      x = x.view(x.shape[0], x.shape[1], self.num_heads, self.head_dim).transpose( 1, 2 )\n",
        "\n",
        "      q = self.query(x)\n",
        "      k = self.key(x)\n",
        "      v = self.value(x)\n",
        "\n",
        "      att = self.att_score(q, k, v)\n",
        "\n",
        "      out = att.transpose(1, 2).reshape(x.shape[0], x.shape[2], self.hidden_dim)\n",
        "\n",
        "      return out\n",
        "\n",
        "  def att_score(self, q, k, v):\n",
        "      attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "      attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "      output = torch.matmul(attn_probs, v)\n",
        "      return output\n"
      ],
      "metadata": {
        "id": "J6-WTGDdEMOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Encoder module for the baseline transformer\n",
        "  \"\"\"\n",
        "  def __init__(self, input_dim, hidden_dim, num_heads, dropout = 0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.multi_head_attention = MultiHeadAttention(hidden_dim, num_heads)\n",
        "\n",
        "    self.feedforward = nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim)\n",
        "    )\n",
        "\n",
        "    self.layer_norm1 = nn.LayerNorm(hidden_dim)\n",
        "    self.layer_norm2 = nn.LayerNorm(hidden_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    att = self.multi_head_attention(x)\n",
        "\n",
        "    norm = self.layer_norm1( x + self.dropout(att))\n",
        "\n",
        "    ff = self.feedforward(norm)\n",
        "\n",
        "    out = self.layer_norm2( norm + self.dropout(ff))\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "UtGYbdyYxce4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "  \"\"\"\n",
        "  Entire baseline transformer\n",
        "  \"\"\"\n",
        "  def __init__(self, input_dim, channels, hidden_dim, num_heads, out_channels, number_of_samples, number_of_classes, dropout = 0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.input_dim = input_dim\n",
        "    self.channels = channels\n",
        "\n",
        "    self.input_embedding = nn.Sequential(\n",
        "        nn.Linear(input_dim * channels, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim)\n",
        "    )\n",
        "\n",
        "    self.ff_layer1 = nn.Linear(hidden_dim, out_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.ff_layer2 = nn.Linear(number_of_samples, number_of_classes - 1)\n",
        "\n",
        "    self.encoder = Encoder(input_dim, hidden_dim, num_heads, dropout)\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.reshape(x.shape[0], x.shape[1], x.shape[2]* x.shape[3])\n",
        "\n",
        "    x = self.input_embedding(x)\n",
        "\n",
        "    x = self.encoder(x)\n",
        "\n",
        "    x = self.ff_layer1(x)\n",
        "    x = self.relu(x)\n",
        "    x = x.squeeze()\n",
        "\n",
        "    x = self.ff_layer2(x)\n",
        "\n",
        "    return self.sigmoid(x).squeeze()"
      ],
      "metadata": {
        "id": "RwxzBDI128V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerPL(pl.LightningModule):\n",
        "  \"\"\"\n",
        "  Pytorch Lignthing class for the baseline transformer\n",
        "  \"\"\"\n",
        "  def __init__(self, input_dim, channels, hidden_dim, num_heads, out_dim, number_of_samples, number_of_classes, dropout = 0.1, lr=1e-3, patience=3, factor = 0.1):\n",
        "    super(TransformerPL, self).__init__()\n",
        "\n",
        "    self.transformer = Transformer(\n",
        "        input_dim,\n",
        "        channels,\n",
        "        hidden_dim,\n",
        "        num_heads,\n",
        "        out_dim,\n",
        "        number_of_samples,\n",
        "        number_of_classes,\n",
        "        dropout,\n",
        "    ).to(device)\n",
        "\n",
        "    self.lr = lr\n",
        "    self.patience = patience\n",
        "    self.factor = factor\n",
        "\n",
        "    self.criterion = nn.BCELoss()\n",
        "\n",
        "    self.accuracy = BinaryAccuracy()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.to(device)\n",
        "    return self.transformer(x)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=self.patience, factor=self.factor)\n",
        "    return optimizer\n",
        "\n",
        "  def training_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    outputs = self.transformer(input)\n",
        "    loss = self.criterion(outputs, label.float())\n",
        "    self.log(\"train_loss\", loss)\n",
        "    print(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    outputs = self.transformer(input)\n",
        "    loss = self.criterion(outputs, label.float())\n",
        "\n",
        "    acc = self.accuracy(outputs, label)\n",
        "    output_values = {\"val_loss\": loss, \"val_acc\" : acc}\n",
        "    self.log_dict(output_values)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    outputs = self.transformer(input)\n",
        "    loss = self.criterion(outputs, label.float())\n",
        "    acc = self.accuracy(outputs, label)\n",
        "\n",
        "    output_values = {\"test_loss\": loss, \"test_acc\" : acc}\n",
        "    self.log_dict(output_values)\n",
        "    return loss\n",
        "\n",
        "  def predict_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    predicted = self.transformer(input)\n",
        "    predicted_label = torch.round(predicted)\n",
        "    t_label.append(label.cpu().detach())\n",
        "    p_label.append(predicted_label.cpu().detach())\n",
        "\n",
        "    return predicted_label"
      ],
      "metadata": {
        "id": "fhaE6-Xb7udz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train"
      ],
      "metadata": {
        "id": "PyAWxQ9mFdot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_data_module = DataModule(\n",
        "        global_variables['single_path'],\n",
        "        global_variables['bifurcating_path']\n",
        "    )\n",
        "\n",
        "transformer = TransformerPL(\n",
        "        global_variables['mv_dimension'],\n",
        "        global_variables['mv_channels'],\n",
        "        global_variables['hidden_dim_mv'],\n",
        "        global_variables['num_heads'],\n",
        "        global_variables['out_channels'],\n",
        "        global_variables['length_data'],\n",
        "        global_variables['num_classes'],\n",
        "        dropout = global_variables['dropout'],\n",
        "        patience = global_variables['patience'],\n",
        "        factor = global_variables['factor'],\n",
        "    )\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 10)\n",
        "\n",
        "trainer.fit(transformer, transformer_data_module)"
      ],
      "metadata": {
        "id": "5HQU2LiFFf64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.test(transformer, transformer_data_module)"
      ],
      "metadata": {
        "id": "iwFQZ_hrUyNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t_label = []\n",
        "p_label = []\n",
        "trainer.predict(transformer, transformer_data_module)\n",
        "\n",
        "confusion_matrix_display(torch.cat(t_label), torch.cat(p_label))"
      ],
      "metadata": {
        "id": "DN8T9eeBwQra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Geometric Algebra Transformer (GATr)\n",
        "\n",
        "The basic components of the Geometric Algebra Transformer are now defined, and in particular:\n",
        "\n",
        "*   Equilinear Layer\n",
        "*   Equilinear Layer Norm\n",
        "*   Geometric attention\n",
        "*   Gated GELU\n",
        "*   Geometric Bilinear Layer\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eiiE7TisrvAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Equilinear Layer"
      ],
      "metadata": {
        "id": "5DrfNI87lV1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EquiLinearLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines the Equilinear Layer using blades\n",
        "    \"\"\"\n",
        "    def __init__(self, input_mv_channels, hidden_mv_dim, blade, blade_len):\n",
        "        super(EquiLinearLayer,self).__init__()\n",
        "\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.rand(hidden_mv_dim,input_mv_channels,blade_len).to(device)\n",
        "         ).to(device)\n",
        "\n",
        "        self.blades = blade\n",
        "        self.blade_len = blade_len\n",
        "\n",
        "    def forward(self,x):\n",
        "        output_mv = torch.einsum(\n",
        "            #h: hidden_mv_dim\n",
        "            #i: input_mv_channels\n",
        "            #b: blade_len\n",
        "            #r: blade_rows\n",
        "            #c: blade_cols\n",
        "\n",
        "            \"h i b, b r c, ... i r -> ... h c\",\n",
        "            self.weights,\n",
        "            self.blades,\n",
        "            x\n",
        "         )\n",
        "        return output_mv"
      ],
      "metadata": {
        "id": "Rm15guvBe-C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Equilayer Normalization"
      ],
      "metadata": {
        "id": "X5qvVhs8lZzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EquilayerNorm(nn.Module):\n",
        "  \"\"\"\n",
        "  This class defines the Normalized Equilinear Layer\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(EquilayerNorm,self).__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    outputs = x / torch.sqrt(torch.mean(inner_product(x, x), dim=-2, keepdim=True))\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "BfjaDF7KlcbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Geometric Attention"
      ],
      "metadata": {
        "id": "ICEvwm4BBoQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Geometric_Multihead_Attention(nn.Module):\n",
        "  \"\"\"\n",
        "  Geometric multi-head attention module for GATr\n",
        "  \"\"\"\n",
        "  def __init__(self, hidden_dim, input_mv_dim, blades, num_heads, out_dim):\n",
        "    super(Geometric_Multihead_Attention, self).__init__()\n",
        "\n",
        "    assert hidden_dim % num_heads == 0, \"emb_dim must be divisible by num_heads\"\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.query =  EquiLinearLayer(\n",
        "                        input_mv_channels = input_mv_dim,\n",
        "                        hidden_mv_dim = hidden_dim * num_heads,\n",
        "                        blade = blades,\n",
        "                        blade_len = blades.shape[0]\n",
        "                    )\n",
        "\n",
        "    self.key =  EquiLinearLayer(\n",
        "                        input_mv_channels = input_mv_dim,\n",
        "                        hidden_mv_dim = hidden_dim ,\n",
        "                        blade = blades,\n",
        "                        blade_len = blades.shape[0]\n",
        "                    )\n",
        "\n",
        "    self.value =  EquiLinearLayer(\n",
        "                        input_mv_channels = input_mv_dim,\n",
        "                        hidden_mv_dim = hidden_dim ,\n",
        "                        blade = blades,\n",
        "                        blade_len = blades.shape[0]\n",
        "                    )\n",
        "\n",
        "    self.output_layer =  EquiLinearLayer(\n",
        "                        input_mv_channels = hidden_dim * num_heads,\n",
        "                        hidden_mv_dim = out_dim,\n",
        "                        blade = blades,\n",
        "                        blade_len = blades.shape[0]\n",
        "                    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    q = self.query(x)\n",
        "    k = self.key(x)\n",
        "    v = self.value(x)\n",
        "\n",
        "    batch_size, items, embed_dim, multivector = q.size()\n",
        "\n",
        "    #split heads\n",
        "    q = q.view(batch_size, items, self.hidden_dim, self.num_heads, multivector).transpose(3,2).transpose(2,1)\n",
        "    k = k.view(batch_size, items, self.hidden_dim, 1, multivector).transpose(3,2).transpose(2,1)\n",
        "    v = v.view(batch_size, items, self.hidden_dim, 1, multivector).transpose(3,2).transpose(2,1)\n",
        "\n",
        "    mask = get_mask_product().int().to(device)\n",
        "\n",
        "    q = q * mask\n",
        "    k = k * mask\n",
        "    v = v\n",
        "\n",
        "    att = self.attention_score(q, k, v) #torch.Size([32, 4, 100, 64, 16])\n",
        "    att = rearrange( att, \"... heads items hidden_dim x -> ... items (heads hidden_dim) x\" )\n",
        "\n",
        "    output = self.output_layer(att)\n",
        "\n",
        "    return output\n",
        "\n",
        "  def attention_score(self, q, k, v):\n",
        "\n",
        "    att_score = inner_product(q, k) / math.sqrt(8 * self.hidden_dim)\n",
        "\n",
        "    att_score = torch.softmax(att_score, dim = 2)\n",
        "\n",
        "    att_score = att_score* v\n",
        "\n",
        "    return att_score"
      ],
      "metadata": {
        "id": "4nyO-n-BJiuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gated GeLU"
      ],
      "metadata": {
        "id": "2mpra8CMZHuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GatedGeLU(nn.Module):\n",
        "  \"\"\"\n",
        "  Gated GELU module for GATr\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(GatedGeLU, self).__init__()\n",
        "\n",
        "    self.GeLU = GELU()\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x1 = x[..., 0]\n",
        "    output = self.GeLU(x1)\n",
        "\n",
        "    return output.unsqueeze(-1) * x\n",
        "\n"
      ],
      "metadata": {
        "id": "1Nl3JrCZa8YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Geometric Bilinear Layer"
      ],
      "metadata": {
        "id": "JrmvLn0CX1Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeometricBilinearLayer(nn.Module):\n",
        "  \"\"\"\n",
        "  Geometric Bilinear Layer module for GATr\n",
        "  \"\"\"\n",
        "  def __init__(self, in_channels, out_channels, blades):\n",
        "    super(GeometricBilinearLayer, self).__init__()\n",
        "\n",
        "    #TODO: FORSE CE NE VANNO 4 INVECE CHE 2 O FORSE NO????\n",
        "    self.input_1 = EquiLinearLayer(\n",
        "                        input_mv_channels = in_channels,\n",
        "                        hidden_mv_dim = out_channels // 2,\n",
        "                        blade = blades,\n",
        "                        blade_len = blades.shape[0]\n",
        "                    )\n",
        "\n",
        "    self.input_2 = EquiLinearLayer(\n",
        "                        input_mv_channels = in_channels,\n",
        "                        hidden_mv_dim = out_channels // 2,\n",
        "                        blade = blades,\n",
        "                        blade_len = blades.shape[0]\n",
        "                    )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    input_1 = self.input_1(x)\n",
        "    input_2 = self.input_2(x)\n",
        "\n",
        "    geometric_prod = geometric_product(input_1, input_2).to(device)\n",
        "\n",
        "    z = torch.mean(x, dim = (1,2), keepdim = True)\n",
        "\n",
        "    equijoin = z[...,-1].unsqueeze(-1) * join_operation(input_1, input_2)\n",
        "\n",
        "    equijoin = equijoin.to(device)\n",
        "\n",
        "    return torch.cat((geometric_prod, equijoin) , dim = -2)\n"
      ],
      "metadata": {
        "id": "Ild1ikj8X34g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Geometric Encoder\n",
        "\n",
        "<center>\n",
        "\n",
        "![Baseline](https://media.licdn.com/dms/image/D4D22AQGX9zX1vw6QIQ/feedshare-shrink_800/0/1693985295396?e=2147483647&v=beta&t=koYJ91QwdwtqrDytXvepUhck7BrkJDU-f-aGpjiywTc)\n",
        "\n",
        "</center>"
      ],
      "metadata": {
        "id": "7YP_cyFUelnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The GATr architecture is composed by an initial equilinear layer, an encoder (enclosed in the gray box in the image above) and a final equilinear layer. The Encoder is defined in the GeometricEncoder class, while the entire architecture is defined in GATr class."
      ],
      "metadata": {
        "id": "fnsz4l1lOP-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeometricEncoder(nn.Module):\n",
        "  \"\"\"\n",
        "  Geometric Encoder for GATr\n",
        "  \"\"\"\n",
        "  def __init__(self, hidden_dim, input_mv_dim, blades, num_heads, out_dim , dropout=0.1):\n",
        "    super(GeometricEncoder, self).__init__()\n",
        "\n",
        "    self.equilinear_layer2 =  EquiLinearLayer(\n",
        "        input_mv_channels = hidden_dim,\n",
        "        hidden_mv_dim = hidden_dim,\n",
        "        blade = blades,\n",
        "        blade_len = blades.shape[0]\n",
        "    )\n",
        "\n",
        "    self.equi_layer_norm1 = EquilayerNorm()\n",
        "\n",
        "    self.geometric_attention = Geometric_Multihead_Attention(hidden_dim, hidden_dim, blades, num_heads, out_dim)\n",
        "\n",
        "    self.equi_layer_norm2 = EquilayerNorm()\n",
        "\n",
        "    self.geometric_bilinear = GeometricBilinearLayer(out_dim, hidden_dim, blades)\n",
        "\n",
        "    self.gated_gelu = GatedGeLU()\n",
        "\n",
        "    self.out_equilinear =  EquiLinearLayer(\n",
        "        input_mv_channels = hidden_dim,\n",
        "        hidden_mv_dim = hidden_dim,\n",
        "        blade = blades,\n",
        "        blade_len = blades.shape[0]\n",
        "    )\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    equi_layer1 = self.equi_layer_norm1(x)\n",
        "\n",
        "    equi_lin2 = self.equilinear_layer2(equi_layer1)\n",
        "\n",
        "    geom_attn = self.geometric_attention(equi_lin2)\n",
        "\n",
        "    res_1 = x + self.dropout(geom_attn)\n",
        "\n",
        "    equi_layer2 = self.equi_layer_norm2(res_1)\n",
        "\n",
        "    geom_bil = self.geometric_bilinear(equi_layer2)\n",
        "\n",
        "    gated_out = self.gated_gelu(geom_bil)\n",
        "\n",
        "    out_equi = self.out_equilinear(gated_out)\n",
        "\n",
        "    res_2 = res_1 + self.dropout(out_equi)\n",
        "\n",
        "    return res_2"
      ],
      "metadata": {
        "id": "NVhUbsPYfA0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GATr"
      ],
      "metadata": {
        "id": "YmAiF5voKDmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GATr(nn.Module):\n",
        "    \"\"\"\n",
        "    This class defines the entire architecture of the geometric transformer\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_dim, channels, blades, num_heads, number_of_samples, number_of_classes, dropout = 0.1):\n",
        "      super(GATr, self).__init__()\n",
        "\n",
        "      self.equilinear_layer1 =  EquiLinearLayer(\n",
        "          input_mv_channels = channels,\n",
        "          hidden_mv_dim = hidden_dim,\n",
        "          blade = blades,\n",
        "          blade_len = blades.shape[0]\n",
        "      )\n",
        "\n",
        "      self.encoder = GeometricEncoder(hidden_dim, channels, blades, num_heads, hidden_dim, dropout=dropout)\n",
        "\n",
        "      self.out_equilinear =  EquiLinearLayer(\n",
        "          input_mv_channels = hidden_dim,\n",
        "          hidden_mv_dim = number_of_classes - 1,\n",
        "          blade = blades,\n",
        "          blade_len = blades.shape[0]\n",
        "      )\n",
        "\n",
        "      self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "      self.linear = nn.Linear(global_variables['mv_dimension'], number_of_classes - 1)\n",
        "\n",
        "      self.relu = nn.ReLU()\n",
        "\n",
        "      self.linear2 = nn.Linear(global_variables['length_data'], number_of_classes - 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      x =  self.equilinear_layer1(x)\n",
        "\n",
        "      enc_out = self.encoder(x)\n",
        "\n",
        "      equi_output = self.out_equilinear(enc_out).squeeze()\n",
        "\n",
        "      x = self.linear(equi_output).squeeze()\n",
        "      x = self.relu(x)\n",
        "      x = self.linear2(x).squeeze()\n",
        "\n",
        "      return self.sigmoid(x)"
      ],
      "metadata": {
        "id": "8dGLx5sxwoX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GATr Pytorch Lightning Module"
      ],
      "metadata": {
        "id": "pxhVQP8qKGzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GATrPL(pl.LightningModule):\n",
        "  \"\"\"\n",
        "  This class defines the pytorch lightning framework for GATr\n",
        "  \"\"\"\n",
        "  def __init__(self, hidden_dim, channels, num_heads, number_of_samples, number_of_classes, blades, lr=1e-3, patience=3, factor = 0.1, dropout = 0.1):\n",
        "    super(GATrPL, self).__init__()\n",
        "\n",
        "    self.blades = blades.to(device)\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.gatr = GATr(\n",
        "        hidden_dim,\n",
        "        channels,\n",
        "        self.blades,\n",
        "        num_heads,\n",
        "        number_of_samples,\n",
        "        number_of_classes,\n",
        "        dropout = self.dropout\n",
        "    ).to(device)\n",
        "\n",
        "    self.lr = lr\n",
        "    self.patience = patience\n",
        "    self.factor = factor\n",
        "    self.criterion = nn.BCELoss()\n",
        "    self.accuracy = BinaryAccuracy()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.to(device)\n",
        "    return self.gatr(x)\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=self.patience, factor=self.factor)\n",
        "    return optimizer\n",
        "\n",
        "  def training_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    outputs = self.gatr(input)\n",
        "    loss = self.criterion(outputs, label.float())\n",
        "    self.log(\"train_loss\", loss)\n",
        "    print(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "    outputs = self.gatr(input)\n",
        "    loss = self.criterion(outputs, label.float())\n",
        "    acc = self.accuracy(outputs, label)\n",
        "    output_values = {\"val_loss\": loss, \"val_acc\" : acc}\n",
        "    self.log_dict(output_values)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "    outputs = self.gatr(input)\n",
        "    loss = self.criterion(outputs, label.float())\n",
        "    acc = self.accuracy(outputs, label)\n",
        "    output_values = {\"test_loss\": loss, \"test_acc\" : acc}\n",
        "    self.log_dict(output_values)\n",
        "    return loss\n",
        "\n",
        "  def predict_step(self, batch):\n",
        "    input, label = batch\n",
        "\n",
        "    input = input.to(device)\n",
        "\n",
        "    predicted = self.gatr(input)\n",
        "    predicted_label = torch.round(predicted)\n",
        "    t_label.append(label.cpu().detach())\n",
        "    p_label.append(predicted_label.cpu().detach())\n",
        "\n",
        "    return predicted_label\n"
      ],
      "metadata": {
        "id": "oq2jdRcqkES2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training of GATr on the training dataset\n",
        "gatr_data_module = DataModule(\n",
        "        global_variables['single_path'],\n",
        "        global_variables['bifurcating_path']\n",
        "    )\n",
        "\n",
        "mv_ones = torch.ones(global_variables['dim_GA'])\n",
        "\n",
        "# extraction of the blades\n",
        "blades = extract_blades(mv_1.cpu().detach(), layout)\n",
        "blades = blade_matrices(blades).to(device)\n",
        "\n",
        "gatr = GATrPL(\n",
        "        global_variables['hidden_dim_mv'],\n",
        "        global_variables['mv_channels'],\n",
        "        global_variables['num_heads'],\n",
        "        global_variables['length_data'],\n",
        "        global_variables['num_classes'],\n",
        "        blades,\n",
        "        patience = global_variables['patience'],\n",
        "        factor = global_variables['factor'],\n",
        "        dropout = global_variables['dropout'],\n",
        "    ).to(device)\n",
        "\n",
        "trainer = pl.Trainer(max_epochs = 20)\n",
        "\n",
        "trainer.fit(gatr, gatr_data_module)"
      ],
      "metadata": {
        "id": "H6mxFQudmd2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test metrics:\n",
        "trainer.test(gatr, gatr_data_module)"
      ],
      "metadata": {
        "id": "cHfBtnCfSI-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=lightning_logs/"
      ],
      "metadata": {
        "id": "0OUHy-h1hAZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predict"
      ],
      "metadata": {
        "id": "T51QHLnhhdk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_label = []\n",
        "p_label = []\n",
        "trainer.predict(gatr, gatr_data_module)\n",
        "\n",
        "confusion_matrix_display(torch.cat(t_label), torch.cat(p_label))"
      ],
      "metadata": {
        "id": "Bb8X3pn8hbzJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}