{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoRaschiatore0123/GATr_Deep_Learning_Project/blob/main/GATr_deep_learning_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "RT7SSYdrEBj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/FedericoRaschiatore0123/GATr_Deep_Learning_Project.git"
      ],
      "metadata": {
        "id": "yRyVdbVkiufV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#librerie\n",
        "!pip install pytorch_lightning --quiet\n",
        "!pip install h5py\n",
        "!pip install trimesh\n",
        "!pip install torch_geometric\n",
        "!pip install pyquaternion\n",
        "!pip install clifford\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch_geometric.data\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import random_split, ConcatDataset, Subset\n",
        "from pyquaternion import Quaternion\n",
        "import clifford as cf\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import h5py\n",
        "import os\n",
        "import trimesh\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG8SPGozwpkB",
        "outputId": "9ec3ef81-4044-41b6-f275-ad309cebbe87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.25.2)\n",
            "Requirement already satisfied: trimesh in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.25.2)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.10/dist-packages (0.9.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyquaternion) (1.25.2)\n",
            "Requirement already satisfied: clifford in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from clifford) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from clifford) (1.11.4)\n",
            "Requirement already satisfied: numba>0.46 in /usr/local/lib/python3.10/dist-packages (from clifford) (0.58.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from clifford) (3.9.0)\n",
            "Requirement already satisfied: sparse in /usr/local/lib/python3.10/dist-packages (from clifford) (0.15.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>0.46->clifford) (0.41.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Global Variables"
      ],
      "metadata": {
        "id": "iI9E2jDSEHKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary of global variables\n",
        "global_variables = {\n",
        "\n",
        "    'single_path' : '/content/GATr_Deep_Learning_Project/single/',\n",
        "    'bifurcating_path' : '/content/GATr_Deep_Learning_Project/bifurcating/',\n",
        "    'batch_size' :  32,\n",
        "    'num_workers' : 2,\n",
        "\n",
        "    'dim_GA' : 16,\n",
        "    'grade_components': [1,4,6,4,1] ##### canc canc canc\n",
        "}"
      ],
      "metadata": {
        "id": "nuLFZjyREJet"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get device"
      ],
      "metadata": {
        "id": "juxtyP3_Dxb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device_name = torch.device(\"cuda\")\n",
        "else:\n",
        "    device_name = torch.device('cpu')"
      ],
      "metadata": {
        "id": "YMMTiCupDwpG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Show data"
      ],
      "metadata": {
        "id": "BtUQ2EPCD5uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_list = os.listdir(global_variables['single_path'])\n",
        "\n",
        "with h5py.File(global_variables['single_path'] + single_list[random.randint(0, len(single_list))] , 'r') as file:\n",
        "\n",
        "    vertices = np.array(file['pos'])\n",
        "    faces = np.array(file['face'])\n",
        "\n",
        "mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
        "mesh.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "NKNytRO4QNcW",
        "outputId": "c0f07d0c-2af4-4e29-8502-3047c621b3aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/GATr_Deep_Learning_Project/single/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c63d8386a979>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msingle_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'single_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'single_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msingle_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/GATr_Deep_Learning_Project/single/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bifurcating_list = os.listdir(global_variables['bifurcating_path'])\n",
        "\n",
        "with h5py.File(global_variables['bifurcating_path'] + bifurcating_list[random.randint(0, len(bifurcating_list))] , 'r') as file:\n",
        "    vertices = np.array(file['pos'])\n",
        "    faces = np.array(file['face'])\n",
        "\n",
        "mesh = trimesh.Trimesh(vertices=vertices, faces=faces)\n",
        "mesh.show()"
      ],
      "metadata": {
        "id": "5jCvEEzl6Yds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_balancing(dataset):\n",
        "  label = []\n",
        "  for _ , element in enumerate(dataset):\n",
        "    label.append(element[-1])\n",
        "\n",
        "  categories = ['Single ' +  str(label.count(0)), 'Bifurcating ' +  str(label.count(1))]\n",
        "\n",
        "  fig, ax = plt.subplots(figsize = (8,5))\n",
        "\n",
        "  bars = ax.bar(\n",
        "      categories,\n",
        "      [label.count(0), label.count(1)],\n",
        "      align = 'center'\n",
        "    )\n",
        "\n",
        "  ax.set_xlabel('Labels')\n",
        "  ax.set_ylabel('Number of occurences')\n",
        "\n",
        "  plt.ylim(ymax = len(label))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "QbFI-8mcrnxL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Geometric Algebra\n",
        "\n",
        "Geometric algebra G_{3,0,1} is characterized by 4 basic elements (e_{0}, e_{1}, e_{2}, e_{3}) that represent planes in the 3D space. These 4 basic elements can be combined through linear combination and geometric transformation to represent geometric objects of different dimensions (planes, lines, points), and transformations of different types (reflections, translations, rotations).\n",
        "\n",
        "G_{3,0,1} indicates that the basis is composed by three elements (e_{1}, e_{2}, e_{3}) that satisfy e_{i}e_{i} = 1 and one (e_{0}) that satisfies e_{0}e_{0} = 0.\n",
        "\n",
        "The basis components of the multivector associated to the G_{3,0,1} algebra are obtained by considering every possible multiplicative combination of the basis elements. Elements of different grade are thus obtained:\n",
        "\n",
        "Grade 0 (1): scalars in the G.A. \\\\\n",
        "Grade 1 (e_{0}, e_{i}): vectors in the G.A. \\\\\n",
        "Grade 2 (e_{0i}, e_{ij}); bivectors in the G.A. \\\\\n",
        "Grade 3 (e_{0ij}, e_{ijk}): trivectors in the G.A. \\\\\n",
        "Grade 4 (e_{0123}): pseudoscalars in the G.A. \\\\\n",
        "\n",
        "The multivector representation associated to the Geometric Algebra G_{3,0,1} will thus be composed of a total of 16 elements.\n",
        "\n",
        "Scalars will be represented by grade 0 elements, planes by grade 1 elements, lines by grade 2 elements, points by grade 3 elements and pseudoscalar by grade 4 elements."
      ],
      "metadata": {
        "id": "r5aiqBKACZqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_pos_mv_16(pos):\n",
        "    \"\"\"\n",
        "    Embeds the pos torch tensor as a 16-dimensional G_{3,0,1} multivector\n",
        "\n",
        "    Args:\n",
        "        pos (torch.Tensor): tensor of input points with shape (n_elements, 3)\n",
        "\n",
        "    Returns:\n",
        "        pos_mv torch.Tensor: tensor of multivectors of dimension 16 with shape (1, n_elements, 1, 16)\n",
        "    \"\"\"\n",
        "    # Positions in Euclidean geometry can be embedded as points in G_{3,0,1} algebra\n",
        "\n",
        "    # Get the number of points and the dimensionality\n",
        "    n_elements = pos.shape[0]\n",
        "    dim = pos.shape[1]\n",
        "\n",
        "    # Create multivector tensor\n",
        "    multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "\n",
        "    multivector[:, 14] = 1 # homogeneous component, e_{123}\n",
        "    multivector[:, 11] = pos[:, 0] # x, e_{023}\n",
        "    multivector[:, 12] = pos[:, 1] # y, e_{013}\n",
        "    multivector[:, 13] = pos[:, 2] # z, e_{012}\n",
        "\n",
        "    pos_mv = multivector.reshape(1,n_elements,1,global_variables['dim_GA'])\n",
        "\n",
        "    return pos_mv"
      ],
      "metadata": {
        "id": "_rOjz5XGE1FD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_face_mv_16(face):\n",
        "    \"\"\"\n",
        "    Embeds the face torch tensor as a 16-dimensional G_{3,0,1} multivector\n",
        "\n",
        "    Input:\n",
        "        face torch.Tensor of size (n_elements, 3)\n",
        "    Output:\n",
        "        mv torch.Tensor of size (1, n_elements, 1, 16)\n",
        "    \"\"\"\n",
        "\n",
        "    # An oriented surface in Euclidean geometry characterized by\n",
        "    #   the normal vector n to the surface itself can be embedded as an oriented\n",
        "    #   plane in G_{3,0,1} algebra\n",
        "\n",
        "\n",
        "    # Get the number of points and the dimensionality of the space\n",
        "    n_elements = face.shape[0]\n",
        "    dim = face.shape[1]\n",
        "\n",
        "    # Create multivector tensor\n",
        "    multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "\n",
        "    multivector[:, 2] = face[:, 0] # e_{1}\n",
        "    multivector[:, 3] = face[:, 1] # e_{2}\n",
        "    multivector[:, 4] = face[:, 2] # e_{3}\n",
        "\n",
        "    face_mv = multivector.reshape(1,n_elements,1,global_variables['dim_GA'])\n",
        "\n",
        "    return face_mv"
      ],
      "metadata": {
        "id": "nFhi2My_E2Bc"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_wss_mv_16(wss):\n",
        "    \"\"\"\n",
        "    Embeds the wss vectors as a 16 dimensional G_{3,0,1} multivector\n",
        "    Input:\n",
        "      wss torch.Tensor of size (n_elements, 3)\n",
        "    Output:\n",
        "      wss_mv torch.Tensor of size (1, n_elements, 1, 16)\n",
        "    \"\"\"\n",
        "\n",
        "    # A 3D vector in the Euclidean space can be embedded as a translation in G_{3,0,1} algebra\n",
        "\n",
        "    n_elements = wss.shape[0]\n",
        "    dim = wss.shape[1]\n",
        "\n",
        "    multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "\n",
        "    multivector[:, 0] = 1\n",
        "    multivector[:, 5] = 0.5*wss[:, 0] # e_{01}\n",
        "    multivector[:, 6] = 0.5*wss[:, 1] # e_{02}\n",
        "    multivector[:, 7] = 0.5*wss[:, 2] # e_{03}\n",
        "\n",
        "    wss_mv = multivector.reshape(1,n_elements,1,global_variables['dim_GA'])\n",
        "\n",
        "    return wss_mv"
      ],
      "metadata": {
        "id": "pUe6BOxLFJrO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_inlet_mv_16(inlet):\n",
        "    \"\"\"\n",
        "    Embeds the inlet torch tensor as a 16 dimensional G_{3,0,1} multivector\n",
        "    Input:\n",
        "        inlet torch.Tensor of size (n_elements, 1)\n",
        "    Output:\n",
        "        inlet_mv torch.Tensor of size (1, n_elements, 1, 16)\n",
        "    \"\"\"\n",
        "    # Inlet indexes can be embedded as scalars in G_{3,0,1} algebra\n",
        "\n",
        "    n_elements = inlet.shape[0]\n",
        "\n",
        "    multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "    multivector[:, 0] = inlet[:]\n",
        "\n",
        "    inlet_mv = multivector.reshape(1, n_elements, 1, global_variables['dim_GA'])\n",
        "\n",
        "    return inlet_mv"
      ],
      "metadata": {
        "id": "7lRxhBE5FPPd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_pressure_mv_16(pressure):\n",
        "  \"\"\"\n",
        "  Embeds the pressure torch tensor as a 16-dimensional G_{3,0,1} multivector\n",
        "  Input:\n",
        "    pressure torch.Tensor of size (n_elements, 1)\n",
        "  Output:\n",
        "    pressure_mv torch.Tensor of size (1, n_elements, 1, 16)\n",
        "  \"\"\"\n",
        "\n",
        "  n_elements = pressure.shape[0]\n",
        "\n",
        "  # Initialize the multivector\n",
        "  multivector = torch.zeros(n_elements, global_variables['dim_GA'])\n",
        "\n",
        "  multivector[:,0] = pressure[:]\n",
        "  pressure_mv = multivector.reshape(1, n_elements, 1, global_variables['dim_GA'])\n",
        "\n",
        "  return pressure_mv"
      ],
      "metadata": {
        "id": "03FIQj20FXPc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_complete_mv_16(sample_path):\n",
        "  \"\"\"\n",
        "  Embeds the artery sample into a concatenation of 5 16-dimensional multivectors in G_{3,0,1}.\n",
        "  Each of the 5 multivectors embeds a different feature of the artery: pos, face, wss, inlet_idcs, pressure\n",
        "  Input:\n",
        "    sample_path: path to the artery sample saved in hdf5 format\n",
        "  Output:\n",
        "    sample_embedding: torch.Tensor of size (1, 50, 5, 16) NOTE: we chose to cut the sample at 50 !!!\n",
        "  \"\"\"\n",
        "\n",
        "  with h5py.File(sample_path, 'r') as f:\n",
        "    # extract torch tensor for pos\n",
        "    pos_data = f['pos'][:100]\n",
        "    pos_torch = torch.tensor(pos_data[:])\n",
        "\n",
        "    # extract torch tensor for face\n",
        "    face_data = f['face'][:100]\n",
        "    face_torch = torch.tensor(face_data[:])\n",
        "\n",
        "    # extract torch tensor for wss\n",
        "    wss_data = f['wss'][:100]\n",
        "    wss_torch = torch.tensor(wss_data[:])\n",
        "\n",
        "    # extract torch tensor for pressure\n",
        "    pressure_data = f['pressure'][:100]\n",
        "    pressure_torch = torch.tensor(pressure_data[:])\n",
        "\n",
        "    # extract torch tensor for inlet_idcs\n",
        "    inlet_data = f['inlet_idcs'][:100]\n",
        "    inlet_torch = torch.tensor(inlet_data[:])\n",
        "\n",
        "  # Get the multivector embeddings for each torch tensor\n",
        "  pos_mv_16 = embed_pos_mv_16(pos_torch)\n",
        "  face_mv_16 = embed_face_mv_16(face_torch)\n",
        "  wss_mv_16 = embed_wss_mv_16(wss_torch)\n",
        "  inlet_mv_16 = embed_inlet_mv_16(inlet_torch)\n",
        "  pressure_mv_16 = embed_pressure_mv_16(pressure_torch)\n",
        "\n",
        "  sample_embedding = torch.cat(\n",
        "      [pos_mv_16, face_mv_16, wss_mv_16, inlet_mv_16, pressure_mv_16], dim = 2)\n",
        "\n",
        "  return sample_embedding"
      ],
      "metadata": {
        "id": "ll-POLsqFh6O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use of embed_complete_mv_16\n",
        "\n",
        "sample_path = \"/content/GATr_Deep_Learning_Project/single/sample_0000.hdf5\"\n",
        "sample_embedding = embed_complete_mv_16(sample_path)\n",
        "print(sample_embedding.shape)"
      ],
      "metadata": {
        "id": "XhspGp72FoxC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "8225817b-f10d-41e2-8eb2-1eba5abf4614"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/content/GATr_Deep_Learning_Project/single/sample_0000.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fe741b671fa6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/GATr_Deep_Learning_Project/single/sample_0000.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msample_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_complete_mv_16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-a1556f04937d>\u001b[0m in \u001b[0;36membed_complete_mv_16\u001b[0;34m(sample_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \"\"\"\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# extract torch tensor for pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpos_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/content/GATr_Deep_Learning_Project/single/sample_0000.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geometric Algebra Transformations"
      ],
      "metadata": {
        "id": "VEtqNCVQGR3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_plane_reflection_mv_16(normal, d):\n",
        "  \"\"\"\n",
        "  Embeds a plane reflection transformation given a normal vector and an origin shift\n",
        "  as a 16-dimensional multivector in G_{3,0,1}\n",
        "  Input:\n",
        "    normal: torch.Tensor (1, 3) normal to the plane\n",
        "    d: origin shift\n",
        "  Output:\n",
        "    pr_mv_16: torch.Tensor multivector of size (1,1,1,16) representing the plane reflection\n",
        "  \"\"\"\n",
        "  # Initialize the multivector\n",
        "  plane_reflection_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  plane_reflection_mv_16[0,1] = d\n",
        "  plane_reflection_mv_16[0,2] = normal[0]\n",
        "  plane_reflection_mv_16[0,3] = normal[1]\n",
        "  plane_reflection_mv_16[0,4] = normal[2]\n",
        "\n",
        "  pr_mv_16 = plane_reflection_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  return pr_mv_16\n",
        "\n"
      ],
      "metadata": {
        "id": "zJ8m35gFGa8J"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_translation_mv_16(t):\n",
        "  \"\"\"\n",
        "  Embeds a translation by a vector t in R^{3} as a 16-dimensional multivector in G_{3,0,1}\n",
        "  Input:\n",
        "    t: torch.Tensor of size (1, 3) representing a translation in the 3D space\n",
        "  Output:\n",
        "    tr_mv_16: torch.Tensor multivector of size (1,1,1,16) representing the translation\n",
        "  \"\"\"\n",
        "  # Initialize the multivector\n",
        "  translation_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  translation_mv_16[0,0] = 1 # homogeneous component\n",
        "  translation_mv_16[0,5] = 0.5*t[0]\n",
        "  translation_mv_16[0,6] = 0.5*t[1]\n",
        "  translation_mv_16[0,7] = 0.5*t[2]\n",
        "\n",
        "  tr_mv_16 = translation_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  return tr_mv_16"
      ],
      "metadata": {
        "id": "C9Vw6dGZGehD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_point_reflection_mv(p):\n",
        "  \"\"\"\n",
        "  Embeds a reflection with respect to a point p in R^{3} as a 16-dimensional multivector in G_{3,0,1}\n",
        "  Input:\n",
        "    p: torch.Tensor of size (1,3) representing a point in 3D\n",
        "  Output:\n",
        "    pt_ref_mv_16: torch.Tensor of size (1,1,1,16) representing the point reflection\n",
        "  \"\"\"\n",
        "  # Initialize the multivector\n",
        "  point_reflection_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  point_reflection_mv_16[0,11] = p[0]\n",
        "  point_reflection_mv_16[0,12] = p[1]\n",
        "  point_reflection_mv_16[0,13] = p[2]\n",
        "  point_reflection_mv_16[0,14] = 1\n",
        "\n",
        "  # Reshape to match the shape of the other multivectors\n",
        "  pt_ref_mv_16 = point_reflection_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  return pt_ref_mv_16"
      ],
      "metadata": {
        "id": "2_7iiqonGjm0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed_quaternion_rotation_mv_16(rot_axis, alpha):\n",
        "  \"\"\"\n",
        "  Embeds a rotation defined by a quaterion through the axis angle rotation representation\n",
        "  Input:\n",
        "    rot_axis: list of size 1x3 representing the axis of the rotation [r1,r2,r3]\n",
        "    alpha: float representing the angle of the rotation\n",
        "  Output:\n",
        "    quat_rot_mv_16: torch.Tensor of size (1,1,1,16) representing a rotation quaternion rotation\n",
        "  \"\"\"\n",
        "  quaternion = Quaternion(axis=rot_axis, angle=alpha)\n",
        "\n",
        "  # Initialize the multivector\n",
        "  quaternion_rotation_mv_16 = torch.zeros(1, global_variables['dim_GA'])\n",
        "\n",
        "  quaternion_rotation_mv_16[0, 0] = quaternion.w\n",
        "  quaternion_rotation_mv_16[0, 8] = quaternion.x\n",
        "  quaternion_rotation_mv_16[0, 9] = quaternion.y\n",
        "  quaternion_rotation_mv_16[0, 10] = quaternion.z\n",
        "\n",
        "  quat_rot_mv_16 = quaternion_rotation_mv_16.reshape(1,1,1,global_variables['dim_GA'])\n",
        "\n",
        "  return quat_rot_mv_16"
      ],
      "metadata": {
        "id": "2drWMshsGoFS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Operations between multivectors\n",
        "- Inner product \\\\\n",
        "- Outer product \\\\\n",
        "- Geometric product \\\\\n",
        "\n",
        "These are calculated using the functions defined in the library Clifford. First, we create an instance of the geometric algebra using clifford. Then, in the three functions defined below, we convert the torch multivectors into clifford multivectors,\n",
        "we calculate the operation of interest and finally express the result back into torch.Tensor format."
      ],
      "metadata": {
        "id": "4GKjApOK4bTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate clifford G_{3,0,1} algebra\n",
        "layout, blades = cf.Cl(p=3, q=0, r=1, firstIdx=0)\n",
        "locals().update(blades)\n",
        "\n",
        "print('PGA blades: ', blades)\n",
        "print('PGA layout: ', layout)"
      ],
      "metadata": {
        "id": "mSOsxD4K6S20",
        "outputId": "b935a363-bcfa-4332-e8d3-a9af130c43bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PGA blades:  {'': 1, 'e0': (1^e0), 'e1': (1^e1), 'e2': (1^e2), 'e3': (1^e3), 'e01': (1^e01), 'e02': (1^e02), 'e03': (1^e03), 'e12': (1^e12), 'e13': (1^e13), 'e23': (1^e23), 'e012': (1^e012), 'e013': (1^e013), 'e023': (1^e023), 'e123': (1^e123), 'e0123': (1^e0123)}\n",
            "PGA layout:  Layout([0, 1, 1, 1], ids=BasisVectorIds.ordered_integers(4, first_index=0), order=BasisBladeOrder.shortlex(4), names=['', 'e0', 'e1', 'e2', 'e3', 'e01', 'e02', 'e03', 'e12', 'e13', 'e23', 'e012', 'e013', 'e023', 'e123', 'e0123'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inner_product_mv(mv_1, mv_2, layout):\n",
        "  \"\"\"\n",
        "  Calculated the multivector that results from the inner product between mv_1 and mv_2\n",
        "  Input:\n",
        "    mv_1: torch.Tensor\n",
        "    mv_2: toch.Tensor\n",
        "    layout: layout feature of the Clifford algebra\n",
        "  Output:\n",
        "    outer_product_mv: torch.Tensor inner product between mv_1 and mv_2\n",
        "  \"\"\"\n",
        "  cf_mv_1 = layout.MultiVector(mv_1.numpy())\n",
        "  cf_mv_2 = layout.MultiVector(mv_2.numpy())\n",
        "\n",
        "  inner_product_mv = cf_mv_1 | cf_mv_2\n",
        "\n",
        "  # Express the result in torch.Tensor format\n",
        "  inner_product_coeffs = list(inner_product_mv.value)\n",
        "  inner_product_torch = torch.tensor(inner_product_coeffs)\n",
        "\n",
        "  return inner_product_torch"
      ],
      "metadata": {
        "id": "BVxtzI8z45df"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outer_product_mv(mv_1, mv_2, layout):\n",
        "  \"\"\"\n",
        "  Calculated the multivector that results from the outer product between mv_1 and mv_2\n",
        "  Input:\n",
        "    mv_1: torch.Tensor\n",
        "    mv_2: toch.Tensor\n",
        "    layout: layout feature of the Clifford algebra\n",
        "  Output:\n",
        "    outer_product_mv: torch.Tensor outer product between mv_1 and mv_2\n",
        "  \"\"\"\n",
        "  cf_mv_1 = layout.MultiVector(mv_1.numpy())\n",
        "  cf_mv_2 = layout.MultiVector(mv_2.numpy())\n",
        "\n",
        "  outer_product_mv = cf_mv_1 ^ cf_mv_2\n",
        "\n",
        "  # Express the result in torch.Tensor format\n",
        "  outer_product_coeffs = list(outer_product_mv.value)\n",
        "  outer_product_torch = torch.tensor(outer_product_coeffs)\n",
        "\n",
        "  return outer_product_torch"
      ],
      "metadata": {
        "id": "bWWNX7VS5AB1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_geometric_product_mv(mv_1, mv_2, layout):\n",
        "  \"\"\"\n",
        "  Calculated the multivector that results from the geometric product between mv_1 and mv_2\n",
        "  Input:\n",
        "    mv_1: torch.Tensor\n",
        "    mv_2: toch.Tensor\n",
        "    layout: layout feature of the Clifford algebra\n",
        "  Output:\n",
        "    outer_product_mv: torch.Tensor geometric product between mv_1 and mv_2\n",
        "  \"\"\"\n",
        "  cf_mv_1 = layout.MultiVector(mv_1.numpy())\n",
        "  cf_mv_2 = layout.MultiVector(mv_2.numpy())\n",
        "\n",
        "  geometric_product_mv = cf_mv_1 * cf_mv_2\n",
        "\n",
        "  # Express the result in torch.Tensor format\n",
        "  geometric_product_coeffs = list(geometric_product_mv.value)\n",
        "  geometric_product_torch = torch.tensor(geometric_product_coeffs)\n",
        "\n",
        "  return geometric_product_torch"
      ],
      "metadata": {
        "id": "ffSdcpOs5DzN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_blades(mv, layout):\n",
        "    # mv: torch.Tensor [1, 16]\n",
        "    cf_mv = layout.MultiVector(mv.numpy())\n",
        "\n",
        "    w_blade_array = []\n",
        "    v_blade_array = []\n",
        "    blade_array = []\n",
        "\n",
        "    grades = len(cf_mv.grades())\n",
        "\n",
        "    for grade in range(grades):\n",
        "        # elements of w_{k} (5 elements)\n",
        "        cf_w_blade = cf_mv(grade)  # mv in clifford\n",
        "        coeffs = list(cf_w_blade.value)\n",
        "        blade_torch = torch.tensor(coeffs)\n",
        "        w_blade_array.append(blade_torch)\n",
        "\n",
        "    for grade in range(grades-1):  # end at num_blades-1\n",
        "        # elements of v_k (4 elements)\n",
        "        cf_blade = cf_mv(grade)\n",
        "        cf_v_blade = e0^cf_blade  # Use the geometric product to extract v-blades\n",
        "        coeffs = list(cf_v_blade.value)\n",
        "        blade_torch = torch.tensor(coeffs)\n",
        "        v_blade_array.append(blade_torch)\n",
        "\n",
        "    return torch.stack(w_blade_array + v_blade_array)"
      ],
      "metadata": {
        "id": "wxy4JuoEGgQn"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of use of the functions above:\n",
        "mv_1 = torch.Tensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])\n",
        "mv_2 = torch.Tensor([16,15,14,13,12,11,10,9,8,7,6,5,4,3,2,1])\n",
        "\n",
        "geometric_prod_mv = get_geometric_product_mv(mv_1,mv_2,layout)\n",
        "print('multivector 1: ', mv_1)\n",
        "print('multivector 2: ', mv_2)\n",
        "print('geometric product mv_1*mv_2: ', geometric_prod_mv)"
      ],
      "metadata": {
        "id": "zHixl4sB7lGs",
        "outputId": "e68a9beb-22a3-4dcc-c1fb-7035a3c3f0db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "multivector 1:  tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
            "        15., 16.])\n",
            "multivector 2:  tensor([16., 15., 14., 13., 12., 11., 10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,\n",
            "         2.,  1.])\n",
            "geometric product mv_1*mv_2:  tensor([ -68., -206.,  120.,  202., -284.,  420.,  176., -524.,  342., -104.,\n",
            "         398.,  444.,  228.,  500.,  404.,  342.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_blades(mv_1, layout)\n",
        "# print(tensor_blade.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E51Oii5lfbd4",
        "outputId": "d31993fd-9762-41aa-97a7-e2ec10db4ca7"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.],\n",
              "        [ 0.,  2.,  3.,  4.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.,  6.,  7.,  8.,  9., 10., 11.,  0.,  0.,  0.,\n",
              "          0.,  0.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 12., 13., 14.,\n",
              "         15.,  0.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0., 16.],\n",
              "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.,  3.,  4.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9., 10., 11.,\n",
              "          0.,  0.],\n",
              "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0., 15.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QUJn_9s1nYDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "ioUmoN9-Vy7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "  def __init__(self, dataset):\n",
        "    self.dataset = dataset\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      return self.dataset[index]"
      ],
      "metadata": {
        "id": "JXCjVpmiwQyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "  def __init__(self, path_single, path_bifurcating):\n",
        "    super(DataModule,self).__init__()\n",
        "\n",
        "    self.single_data_path = path_single\n",
        "    self.bifurcating_data_path = path_bifurcating\n",
        "    self.dataset = None\n",
        "\n",
        "  def prepare_data(self):\n",
        "\n",
        "    single_dataset, label_single = self.load_data(self.single_data_path,  bifurcating=False)\n",
        "    bifurcating_dataset, label_bifurcating = self.load_data(self.bifurcating_data_path,  bifurcating=True)\n",
        "    indices = torch.randperm(label_single.shape[0] + label_bifurcating.shape[0])\n",
        "\n",
        "    self.dataset = self.shuffle_and_combine_datasets(single_dataset, bifurcating_dataset, indices)\n",
        "    self.label = self.shuffle_and_combine_datasets(label_single, label_bifurcating, indices)\n",
        "\n",
        "  def setup(self):\n",
        "\n",
        "    train, validation, test = self.split_dataset(list(zip(self.dataset, self.label)))\n",
        "\n",
        "    self.train_dataset = train\n",
        "    self.validation_dataset = validation\n",
        "    self.test_dataset = test\n",
        "\n",
        "  def load_data(self, path, bifurcating=False):\n",
        "    data = []\n",
        "    for file in os.listdir(path):\n",
        "        data.append(embed_complete_mv_16(path + file))\n",
        "\n",
        "    label = torch.ones(len(data)) if bifurcating else torch.zeros(len(data))\n",
        "    data = torch.stack(data).squeeze()\n",
        "\n",
        "    return data , label\n",
        "\n",
        "\n",
        "  def shuffle_and_combine_datasets(self, dataset1, dataset2, indices):\n",
        "\n",
        "      combined_dataset = ConcatDataset([dataset1, dataset2])\n",
        "      shuffled_dataset = Subset(combined_dataset, indices)\n",
        "\n",
        "      return shuffled_dataset\n",
        "\n",
        "  def split_dataset(self, dataset, train_ratio=0.7, validation_ratio=0.2, test_ratio=0.1):\n",
        "\n",
        "      total_size = len(dataset)\n",
        "      train_size = int(total_size * train_ratio)\n",
        "      validation_size = int(total_size * validation_ratio)\n",
        "      test_size = total_size - train_size - validation_size\n",
        "\n",
        "      train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
        "\n",
        "      return train_dataset, validation_dataset, test_dataset\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      return DataLoader(\n",
        "          self.train_dataset,\n",
        "          shuffle = True,\n",
        "          batch_size = global_variables['batch_size'],\n",
        "          num_workers = global_variables['num_workers']\n",
        "        )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "      return DataLoader(\n",
        "          self.validation_dataset,\n",
        "          shuffle = False,\n",
        "          batch_size = global_variables['batch_size'],\n",
        "          num_workers = global_variables['num_workers']\n",
        "        )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "      return DataLoader(\n",
        "          self.test_dataset,\n",
        "          shuffle = False,\n",
        "          batch_size = global_variables['batch_size'],\n",
        "          num_workers = global_variables['num_workers']\n",
        "        )\n",
        "\n",
        "  def train_dataset(self):\n",
        "    return self.train_dataset\n",
        "\n",
        "  def val_dataset(self):\n",
        "    return self.val_dataset\n",
        "\n",
        "  def test_dataset(self):\n",
        "    return self.test_dataset"
      ],
      "metadata": {
        "id": "vSkUkYzetikG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module_prove = DataModule(global_variables['single_path'], global_variables['bifurcating_path'])\n",
        "\n",
        "data_module_prove.prepare_data()\n",
        "data_module_prove.setup()\n",
        "train_dataloader = data_module_prove.train_dataloader()"
      ],
      "metadata": {
        "id": "5KWJxgI_N30b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_balancing(data_module_prove.train_dataset)"
      ],
      "metadata": {
        "id": "7NdgN0lEq4og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Geometric Algebra Transformer"
      ],
      "metadata": {
        "id": "eiiE7TisrvAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(iter(train_dataloader))[0].shape)"
      ],
      "metadata": {
        "id": "js8pf2fDpMge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.tensor(list(blades.values())).shape)"
      ],
      "metadata": {
        "id": "yGgCV_0er0Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%%%%%%%%%%%"
      ],
      "metadata": {
        "id": "uQmucrZwW0IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EquiLinearLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Equivariant Linear Layer.\n",
        "\n",
        "    Args:\n",
        "        input_mv_channels (int): number of input channels in the multivector\n",
        "        hidden_mv_dim (int): number of output channels in the multivector\n",
        "        blade (torch.Tensor): blade tensor representing the geometric entity\n",
        "        blade_len (int): length of the blade tensor\n",
        "\n",
        "    Attributes:\n",
        "        blade (torch.Tensor): blade tensor representing blade operator\n",
        "        weights (nn.Parameter): learnable weights for the linear layer\n",
        "\n",
        "    Methods:\n",
        "        forward(x): computes the forward pass of the equivariant linear layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,input_mv_channels,hidden_mv_dim,blade,blade_len):\n",
        "        super(EquiLinearLayer,self).__init__()\n",
        "        self.blade = blade\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.rand(hidden_mv_dim,input_mv_channels,blade_len,device = device)\n",
        "         )\n",
        "\n",
        "    def forward(self,x):\n",
        "        output_mv = torch.einsum(\n",
        "            \"j i b, b x y, ... i x -> ... j y\",\n",
        "            self.weights,\n",
        "            self.blade,\n",
        "            x\n",
        "         )\n",
        "        return output_mv"
      ],
      "metadata": {
        "id": "2oxirVnPT1uB"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "blade = blade_operator().to(device)\n",
        "blade_len = blade.shape[0]\n",
        "\n",
        "equi_linear = EquiLinearLayer(\n",
        "    input_mv_channels = input_mv.shape[-2],\n",
        "    hidden_mv_dim = global_var['hidden_dim'],\n",
        "    blade = blade,\n",
        "    blade_len = blade_len\n",
        ").to(device)\n",
        "\n",
        "\n",
        "equilayer = EquiLinearLayer(blade, )"
      ],
      "metadata": {
        "id": "VQ8K7a6JT4w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blade_operator():\n",
        "    \"\"\"\n",
        "    Generates a blade operator matrix for the geometric algebra\n",
        "\n",
        "    Args:\n",
        "        None\n",
        "\n",
        "    Returns:\n",
        "        (torch.Tensor): Blade operator matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    mv_dimension = global_variables['dim_GA']\n",
        "    blade_shape = (mv_dimension,mv_dimension)\n",
        "\n",
        "    coordinates = []\n",
        "    start = 0\n",
        "    for length in range(global_variables['dim_GA']):\n",
        "        coordinates.append(list(range(start, start + length)))\n",
        "        start += length\n",
        "\n",
        "    coord_permutations = [\n",
        "        [[0,1]],\n",
        "        [[2,5],[3,6],[4,7]],\n",
        "        [[8,11],[9,12],[10,13]],\n",
        "        [[14,15]]\n",
        "     ]\n",
        "    blade_mask = []\n",
        "\n",
        "    w_dimension = len(global_variables['grade_components'])\n",
        "    for k_grade in range(w_dimension):\n",
        "        w_blade = torch.zeros(blade_shape) # per ogni grado di k genero una w_blade\n",
        "        for coordinate in coordinates[k_grade]:\n",
        "            w_blade[coordinate, coordinate] = 1.0\n",
        "        blade_mask.append(w_blade.unsqueeze(0))\n",
        "\n",
        "    v_dimension = len(global_variables['grade_components']) - 1\n",
        "    for k_grade in range(v_dimension):\n",
        "        v_blade = torch.zeros(blade_shape)\n",
        "        for coord_to,coord_from in coord_permutations[k_grade]:\n",
        "            v_blade[coord_from, coord_to] = 1.0\n",
        "        blade_mask.append(v_blade.unsqueeze(0))\n",
        "\n",
        "    blade_operator = torch.cat(blade_mask,dim = 0)\n",
        "\n",
        "    return blade_operator"
      ],
      "metadata": {
        "id": "bs4y6f8IW2Iy"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EquiLinearLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Equivariant Linear Layer.\n",
        "\n",
        "    Args:\n",
        "        input_mv_channels (int): number of input channels in the multivector\n",
        "        hidden_mv_dim (int): number of output channels in the multivector\n",
        "        blade (torch.Tensor): blade tensor representing the geometric entity\n",
        "        blade_len (int): length of the blade tensor\n",
        "\n",
        "    Attributes:\n",
        "        blade (torch.Tensor): blade tensor representing blade operator\n",
        "        weights (nn.Parameter): learnable weights for the linear layer\n",
        "\n",
        "    Methods:\n",
        "        forward(x): computes the forward pass of the equivariant linear layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,input_mv_channels,hidden_mv_dim,blade,blade_len):\n",
        "        super(EquiLinearLayer,self).__init__()\n",
        "        self.blade = blade\n",
        "        self.weights = nn.Parameter(\n",
        "            torch.rand(hidden_mv_dim,input_mv_channels,blade_len)\n",
        "         )\n",
        "\n",
        "    def forward(self,x):\n",
        "        output_mv = torch.einsum(\n",
        "            \"j i b, b x y, ... i x -> ... j y\",\n",
        "            self.weights,\n",
        "            self.blade,\n",
        "            x\n",
        "         )\n",
        "        return output_mv"
      ],
      "metadata": {
        "id": "wsBeP7MKXSWw"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blade = blade_operator()\n",
        "print(blade.shape)\n",
        "blade_len = blade.shape[0]\n",
        "\n",
        "input_mv = torch.rand([32, 50, 4, 16])\n",
        "equi_linear = EquiLinearLayer(\n",
        "    input_mv_channels = input_mv.shape[-2],\n",
        "    hidden_mv_dim = 8,\n",
        "    blade = blade,\n",
        "    blade_len = blade_len\n",
        ")\n",
        "\n",
        "equi_linear(input_mv).shape"
      ],
      "metadata": {
        "id": "2UmdJjrDXWwh",
        "outputId": "9db9a781-7fb9-4f21-efdd-be3d1c1a5d00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([9, 16, 16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 50, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    }
  ]
}